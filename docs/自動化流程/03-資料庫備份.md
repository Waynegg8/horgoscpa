# 03 - è³‡æ–™åº«å‚™ä»½ (Database Backup)

**Cron Jobåç¨±ï¼š** Database Backup  
**åŸ·è¡Œé »ç‡ï¼š** æ¯å¤©å‡Œæ™¨ 3:00 AM  
**Cronè¡¨é”å¼ï¼š** `0 3 * * *`  
**æœ€å¾Œæ›´æ–°ï¼š** 2025å¹´10æœˆ27æ—¥

---

## åŠŸèƒ½æ¦‚è¿°

æ¯æ—¥è‡ªå‹•å°‡ Cloudflare D1 è³‡æ–™åº«å®Œæ•´åŒ¯å‡ºç‚º SQL æª”æ¡ˆï¼Œä¸¦ä¸Šå‚³è‡³ R2 å„²å­˜æ¡¶ï¼Œä½œç‚ºç½é›£æ¢å¾©æ©Ÿåˆ¶ã€‚

**ç›®çš„ï¼š**
- é˜²æ­¢è³‡æ–™éºå¤±
- æä¾›æ™‚é–“é»æ¢å¾©èƒ½åŠ›
- ç¬¦åˆè³‡æ–™ä¿è­·è¦ç¯„

---

## åŸ·è¡Œé‚è¼¯

### æ­¥é©Ÿ 1ï¼šåŒ¯å‡ºè³‡æ–™åº«

```typescript
import { D1Database, R2Bucket } from '@cloudflare/workers-types';

async function exportDatabase(db: D1Database): Promise<string> {
  const tables = [
    'Users', 'Clients', 'TimeLogs', 'ActiveTasks', 'ActiveTaskStages',
    'LeaveApplications', 'LeaveBalances', 'LeaveTypes', 'Holidays',
    'OvertimeRates', 'ServiceTemplates', 'ClientServices',
    'TaskTemplates', 'TaskStageTemplates', 'SOPDocuments',
    'KnowledgeBase', 'ModulePermissions', 'SystemSettings'
  ];
  
  let sqlDump = '';
  
  // æ·»åŠ æ–‡ä»¶é ­
  sqlDump += `-- Database Backup\n`;
  sqlDump += `-- Generated: ${new Date().toISOString()}\n`;
  sqlDump += `-- Source: Cloudflare D1\n\n`;
  
  // åŒ¯å‡ºæ¯å€‹è¡¨æ ¼
  for (const table of tables) {
    sqlDump += `\n-- Table: ${table}\n`;
    sqlDump += await exportTable(db, table);
  }
  
  return sqlDump;
}
```

---

### æ­¥é©Ÿ 2ï¼šåŒ¯å‡ºå–®å€‹è¡¨æ ¼

```typescript
async function exportTable(db: D1Database, tableName: string): Promise<string> {
  // ç²å–è¡¨çµæ§‹
  const schema = await db.prepare(`
    SELECT sql FROM sqlite_master 
    WHERE type='table' AND name=?
  `).bind(tableName).first();
  
  if (!schema) {
    return `-- Table ${tableName} not found\n`;
  }
  
  let sql = `DROP TABLE IF EXISTS ${tableName};\n`;
  sql += `${schema.sql};\n\n`;
  
  // ç²å–æ‰€æœ‰è³‡æ–™
  const rows = await db.prepare(`SELECT * FROM ${tableName}`).all();
  
  if (rows.results.length === 0) {
    return sql + `-- No data in ${tableName}\n`;
  }
  
  // ç”Ÿæˆ INSERT èªå¥
  const columns = Object.keys(rows.results[0]);
  sql += `INSERT INTO ${tableName} (${columns.join(', ')}) VALUES\n`;
  
  const values = rows.results.map(row => {
    const vals = columns.map(col => {
      const val = row[col];
      if (val === null) return 'NULL';
      if (typeof val === 'string') return `'${val.replace(/'/g, "''")}'`;
      return val;
    });
    return `  (${vals.join(', ')})`;
  });
  
  sql += values.join(',\n');
  sql += ';\n';
  
  return sql;
}
```

---

### æ­¥é©Ÿ 3ï¼šä¸Šå‚³è‡³ R2

```typescript
async function uploadToR2(
  r2: R2Bucket,
  sqlDump: string,
  timestamp: Date
): Promise<string> {
  const year = timestamp.getFullYear();
  const month = (timestamp.getMonth() + 1).toString().padStart(2, '0');
  const day = timestamp.getDate().toString().padStart(2, '0');
  
  const filename = `backups/${year}/${month}/db_${year}-${month}-${day}.sql`;
  
  // ä¸Šå‚³åˆ° R2
  await r2.put(filename, sqlDump, {
    httpMetadata: {
      contentType: 'application/sql',
    },
    customMetadata: {
      timestamp: timestamp.toISOString(),
      size: sqlDump.length.toString()
    }
  });
  
  console.log(`âœ“ Backup uploaded: ${filename} (${(sqlDump.length / 1024 / 1024).toFixed(2)} MB)`);
  
  return filename;
}
```

**R2 å„²å­˜çµæ§‹ï¼š**
```
backups/
â”œâ”€â”€ 2024/
â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”œâ”€â”€ db_2024-01-01.sql
â”‚   â”‚   â”œâ”€â”€ db_2024-01-02.sql
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 02/
â”‚   â””â”€â”€ ...
â””â”€â”€ 2025/
    â””â”€â”€ ...
```

---

### æ­¥é©Ÿ 4ï¼šæ¸…ç†èˆŠå‚™ä»½

```typescript
async function cleanupOldBackups(r2: R2Bucket, retentionDays: number = 30): Promise<void> {
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - retentionDays);
  
  // åˆ—å‡ºæ‰€æœ‰å‚™ä»½
  const list = await r2.list({ prefix: 'backups/' });
  
  let deletedCount = 0;
  
  for (const object of list.objects) {
    // å¾æª”æ¡ˆåå–å¾—æ—¥æœŸï¼šbackups/2024/01/db_2024-01-01.sql
    const match = object.key.match(/db_(\d{4}-\d{2}-\d{2})\.sql$/);
    if (!match) continue;
    
    const fileDate = new Date(match[1]);
    
    if (fileDate < cutoffDate) {
      await r2.delete(object.key);
      console.log(`âœ“ Deleted old backup: ${object.key}`);
      deletedCount++;
    }
  }
  
  console.log(`Cleaned up ${deletedCount} old backups (retention: ${retentionDays} days)`);
}
```

---

## å®Œæ•´åŸ·è¡Œæµç¨‹

```typescript
export async function databaseBackup(env: Env): Promise<Response> {
  const startTime = Date.now();
  
  try {
    console.log('Starting database backup...');
    
    // 1. åŒ¯å‡ºè³‡æ–™åº«
    const sqlDump = await exportDatabase(env.DB);
    
    // 2. å£“ç¸®ï¼ˆå¯é¸ï¼‰
    const compressed = await compress(sqlDump);
    
    // 3. ä¸Šå‚³åˆ° R2
    const filename = await uploadToR2(env.BACKUP_BUCKET, compressed, new Date());
    
    // 4. æ¸…ç†èˆŠå‚™ä»½
    await cleanupOldBackups(env.BACKUP_BUCKET, 30);
    
    // 5. è¨˜éŒ„æˆåŠŸ
    const duration = Date.now() - startTime;
    const metrics = {
      filename,
      size: compressed.length,
      duration,
      timestamp: new Date().toISOString()
    };
    
    await env.DB.prepare(`
      INSERT INTO AuditLogs (action, details, created_at)
      VALUES ('database_backup', ?, datetime('now'))
    `).bind(JSON.stringify(metrics)).run();
    
    console.log(`Backup completed in ${duration}ms`);
    
    return new Response(JSON.stringify({ success: true, ...metrics }), {
      headers: { 'Content-Type': 'application/json' }
    });
    
  } catch (error) {
    console.error('Backup failed:', error);
    
    // è¨˜éŒ„å¤±æ•—
    await env.DB.prepare(`
      INSERT INTO AuditLogs (action, details, created_at)
      VALUES ('database_backup_failed', ?, datetime('now'))
    `).bind(error.message).run();
    
    return new Response(JSON.stringify({ success: false, error: error.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
}
```

---

## è³‡æ–™å£“ç¸®ï¼ˆå¯é¸ï¼‰

```typescript
import { gzip } from 'pako';  // æˆ–ä½¿ç”¨å…¶ä»–å£“ç¸®åº«

async function compress(data: string): Promise<Uint8Array> {
  const encoder = new TextEncoder();
  const bytes = encoder.encode(data);
  const compressed = gzip(bytes);
  
  console.log(`Original: ${(bytes.length / 1024 / 1024).toFixed(2)} MB`);
  console.log(`Compressed: ${(compressed.length / 1024 / 1024).toFixed(2)} MB`);
  console.log(`Ratio: ${((1 - compressed.length / bytes.length) * 100).toFixed(1)}%`);
  
  return compressed;
}
```

**å£“ç¸®æ•ˆæœï¼š**
- SQL æ–‡ä»¶é€šå¸¸å¯å£“ç¸® 70-80%
- 10MB SQL â†’ 2-3MB gzip
- ç¯€çœ R2 å„²å­˜æˆæœ¬

---

## æ¢å¾©è³‡æ–™

### æ‰‹å‹•æ¢å¾©

```bash
# 1. å¾ R2 ä¸‹è¼‰å‚™ä»½
wrangler r2 object get BUCKET_NAME/backups/2024/01/db_2024-01-01.sql --file=backup.sql

# 2. è§£å£“ç¸®ï¼ˆå¦‚æœæœ‰å£“ç¸®ï¼‰
gunzip backup.sql.gz

# 3. åŒ¯å…¥åˆ° D1
wrangler d1 execute DB_NAME --file=backup.sql
```

### è‡ªå‹•æ¢å¾©ï¼ˆAPIï¼‰

```typescript
app.post('/api/v1/admin/restore-backup', requireAdmin, async (c) => {
  const { filename } = await c.req.json();
  
  // å¾ R2 ä¸‹è¼‰
  const backup = await c.env.BACKUP_BUCKET.get(filename);
  if (!backup) {
    return c.json({ success: false, error: 'Backup not found' }, 404);
  }
  
  const sqlContent = await backup.text();
  
  // åŸ·è¡Œ SQLï¼ˆéœ€è¦åˆ†æ‰¹åŸ·è¡Œï¼‰
  const statements = sqlContent.split(';\n').filter(s => s.trim());
  
  for (const stmt of statements) {
    await c.env.DB.prepare(stmt).run();
  }
  
  return c.json({ success: true, restored: statements.length });
});
```

---

## ç›£æ§èˆ‡å‘Šè­¦

### å‚™ä»½å¤±æ•—å‘Šè­¦

```typescript
if (backupFailed) {
  await sendAlert({
    to: 'admin@firm.com',
    subject: 'ğŸš¨ è³‡æ–™åº«å‚™ä»½å¤±æ•—',
    body: `
      æ™‚é–“ï¼š${new Date().toISOString()}
      éŒ¯èª¤ï¼š${error.message}
      
      è«‹ç«‹å³æª¢æŸ¥å‚™ä»½ç³»çµ±ã€‚
    `
  });
}
```

### å‚™ä»½æˆåŠŸé€šçŸ¥ï¼ˆæ¯é€±ï¼‰

```typescript
// æ¯é€±ä¸€ç™¼é€ä¸Šé€±å‚™ä»½å ±å‘Š
if (today.getDay() === 1) {
  const lastWeekBackups = await listBackupsLastWeek();
  
  await sendReport({
    to: 'admin@firm.com',
    subject: 'ğŸ“Š æ¯é€±å‚™ä»½å ±å‘Š',
    body: `
      ä¸Šé€±æˆåŠŸå‚™ä»½ï¼š${lastWeekBackups.length} æ¬¡
      å¹³å‡å¤§å°ï¼š${avgSize} MB
      ç¸½å„²å­˜ï¼š${totalSize} MB
    `
  });
}
```

---

## æ•ˆèƒ½å„ªåŒ–

### å¢é‡å‚™ä»½ï¼ˆé€²éšï¼‰

```typescript
// åªå‚™ä»½æœ‰è®Šæ›´çš„è¡¨æ ¼
const lastBackupTime = await getLastBackupTime();

for (const table of tables) {
  const hasChanges = await db.prepare(`
    SELECT COUNT(*) as count FROM ${table}
    WHERE updated_at > ?
  `).bind(lastBackupTime).first();
  
  if (hasChanges.count > 0) {
    await exportTable(db, table);
  } else {
    console.log(`Skipping ${table} (no changes)`);
  }
}
```

---

## å®‰å…¨æ€§è€ƒé‡

### åŠ å¯†å‚™ä»½ï¼ˆå»ºè­°ï¼‰

```typescript
import { encrypt } from './crypto';

// åŠ å¯† SQL å…§å®¹
const encrypted = await encrypt(sqlDump, env.BACKUP_ENCRYPTION_KEY);

await r2.put(filename, encrypted, {
  customMetadata: {
    encrypted: 'true',
    algorithm: 'AES-256-GCM'
  }
});
```

### è¨ªå•æ§åˆ¶

```typescript
// R2 Bucket è¨­å®š
// - ç§æœ‰è¨ªå•ï¼ˆä¸å…¬é–‹ï¼‰
// - åªæœ‰ Worker å¯è¨ªå•
// - ç®¡ç†å“¡ API éœ€è¦é©—è­‰
```

---

## ç›¸é—œæ–‡æª”

- [éƒ¨ç½²æŒ‡å—ï¼šç’°å¢ƒè¨­å®š](../éƒ¨ç½²æŒ‡å—/ç’°å¢ƒè¨­å®š.md)
- [Cloudflare R2 æ–‡æª”](https://developers.cloudflare.com/r2/)

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025å¹´10æœˆ27æ—¥  
**æ–‡æª”ç‰ˆæœ¬ï¼š** 2.0ï¼ˆæ¨¡å¡ŠåŒ–é‡çµ„ç‰ˆï¼‰

