name: 部落格自動化處理

on:
  workflow_dispatch:
    inputs:
      process_word:
        description: '處理Word文檔'
        required: true
        default: 'true'
        type: boolean
      update_json:
        description: '更新JSON文件'
        required: true
        default: 'true'
        type: boolean
      force_process:
        description: '強制重新處理所有文件'
        required: false
        default: 'false'
        type: boolean
      debug_mode:
        description: '啟用調試模式'
        required: false
        default: 'false'
        type: boolean
  
  push:
    paths:
      - 'word-docs/**/*.docx'
      - 'scripts/**/*.py'
      - '.github/workflows/blog-automation.yml'
      - '.github/scripts/**/*.py'
  
  schedule:
    - cron: '0 1 * * *'

env:
  PYTHON_VERSION: '3.11'
  DEEPL_API_KEY: ${{ secrets.DEEPL_API_KEY }}

jobs:
  blog-automation:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: write
      pages: write
      id-token: write
    
    steps:
      - name: 檢出代碼
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: 設置Git配置
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global core.autocrlf false
          git config --global core.filemode false
      
      - name: 設置Python環境
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: 安裝Python依賴
        run: |
          python -m pip install --upgrade pip setuptools wheel
          
          # 安裝requirements.txt中的依賴
          if [ -f "requirements.txt" ]; then
            echo "安裝requirements.txt中的依賴..."
            pip install -r requirements.txt
          else
            # 安裝基本依賴
            pip install loguru python-docx beautifulsoup4 requests jieba pathlib
          fi
          
          # 驗證關鍵模組安裝
          python -c "
          import sys
          required_modules = ['loguru', 'docx', 'bs4', 'requests', 'jieba']
          missing = []
          for module in required_modules:
              try:
                  __import__(module)
                  print(f'✓ {module}')
              except ImportError:
                  missing.append(module)
                  print(f'✗ {module}')
          
          if missing:
              print(f'缺少模組: {missing}')
              sys.exit(1)
          else:
              print('所有必要模組已安裝')
          "

      - name: 初始化項目環境
        run: |
          echo "=== 初始化項目環境 ==="
          
          # 確保必要目錄存在
          mkdir -p {blog,assets/{data,images/blog},word-docs/processed,video,logs}
          
          # 檢查核心Python文件是否存在
          echo "檢查核心文件..."
          
          # 檢查主要模組文件
          CORE_FILES=("scripts/word_processor.py" "scripts/html_generator.py" "scripts/content_manager.py" "scripts/json_generator.py" "scripts/translator.py" "scripts/utils.py")
          GITHUB_SCRIPTS=(".github/scripts/update_videos.py" ".github/scripts/generate_sitemap.py" ".github/scripts/move_processed_files.py" ".github/scripts/update_blog_json.py")
          
          MISSING_FILES=()
          
          for file in "${CORE_FILES[@]}"; do
            if [ -f "$file" ]; then
              echo "✓ $file"
            else
              echo "✗ $file (缺失)"
              MISSING_FILES+=("$file")
            fi
          done
          
          for file in "${GITHUB_SCRIPTS[@]}"; do
            if [ -f "$file" ]; then
              echo "✓ $file"
            else
              echo "✗ $file (缺失)"
              MISSING_FILES+=("$file")
            fi
          done
          
          if [ ${#MISSING_FILES[@]} -gt 0 ]; then
            echo "警告: 發現 ${#MISSING_FILES[@]} 個缺失文件"
            echo "缺失文件: ${MISSING_FILES[*]}"
            echo "將使用內建備用方案"
          else
            echo "所有核心文件檢查通過"
          fi
          
          # 初始化配置文件
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          # 確保assets/data目錄存在
          assets_data = Path('assets/data')
          assets_data.mkdir(parents=True, exist_ok=True)
          
          # 創建基本配置文件
          configs = {
              'translation_dict.json': {
                  "translations": {
                      "稅務": "tax", "保險": "insurance", "會計": "accounting",
                      "企業": "business", "投資": "investment", "理財": "financial-planning",
                      "節稅": "tax-saving", "規劃": "planning", "申報": "filing",
                      "法規": "regulation", "個人": "personal", "公司": "corporate",
                      "所得稅": "income-tax", "營業稅": "business-tax", "遺產稅": "estate-tax",
                      "指南": "guide", "攻略": "tips", "解析": "analysis", "案例": "case-study",
                      "合建分屋": "joint-construction", "合理分配": "tax-allocation",
                      "稅務規劃": "tax-planning", "會計實務": "accounting-practice",
                      "實務": "practice", "策略": "strategy", "優化": "optimization"
                  },
                  "last_updated": None
              },
              'processed_files.json': {"files": []},
              'categories.json': {
                  "categories": [
                      {"slug": "tax", "name": "稅務相關", "count": 0},
                      {"slug": "insurance", "name": "保險規劃", "count": 0},
                      {"slug": "accounting", "name": "會計實務", "count": 0},
                      {"slug": "business", "name": "企業服務", "count": 0}
                  ]
              },
              'tags.json': {"tags": []},
              'keyword_dict.json': {
                  "categories": {
                      "tax": {"name": "稅務相關", "keywords": ["稅務", "稅法", "報稅", "節稅", "所得稅", "營業稅", "遺產稅", "贈與稅"]},
                      "insurance": {"name": "保險規劃", "keywords": ["保險", "保單", "受益人", "要保人", "人壽保險", "保險給付"]},
                      "accounting": {"name": "會計實務", "keywords": ["會計", "帳務", "財報", "審計", "記帳", "財務"]},
                      "business": {"name": "企業服務", "keywords": ["企業", "公司", "營運", "投資", "創業", "管理"]}
                  },
                  "tags": {
                      "planning": {"name": "規劃", "keywords": ["規劃", "策略", "方案"]},
                      "filing": {"name": "申報", "keywords": ["申報", "申請", "處理"]},
                      "regulation": {"name": "法規", "keywords": ["法規", "法律", "條文", "辦法"]}
                  }
              }
          }
          
          for filename, content in configs.items():
              file_path = assets_data / filename
              if not file_path.exists():
                  with open(file_path, 'w', encoding='utf-8') as f:
                      json.dump(content, f, ensure_ascii=False, indent=2)
                  print(f'創建配置文件: {filename}')
              else:
                  print(f'配置文件已存在: {filename}')
          
          print('項目環境初始化完成')
          EOF

      - name: 檢查Word文檔
        id: check-documents
        run: |
          echo "=== 檢查Word文檔 ==="
          
          if [ -d "word-docs" ]; then
            DOCX_COUNT=$(find word-docs -maxdepth 1 -name "*.docx" ! -name "~$*" 2>/dev/null | wc -l)
            DOC_COUNT=$(find word-docs -maxdepth 1 -name "*.doc" ! -name "~$*" 2>/dev/null | wc -l)
            TOTAL_COUNT=$((DOCX_COUNT + DOC_COUNT))
            
            echo "發現Word文檔："
            echo "  - .docx 文件: $DOCX_COUNT 個"
            echo "  - .doc 文件: $DOC_COUNT 個"
            echo "  - 總計: $TOTAL_COUNT 個"
            
            if [ "$TOTAL_COUNT" -gt 0 ]; then
              echo "has_docs=true" >> $GITHUB_OUTPUT
              echo "doc_count=$TOTAL_COUNT" >> $GITHUB_OUTPUT
              
              echo "文檔列表："
              find word-docs -maxdepth 1 \( -name "*.docx" -o -name "*.doc" \) ! -name "~$*" | sort | while read file; do
                echo "  - $(basename "$file")"
              done
            else
              echo "has_docs=false" >> $GITHUB_OUTPUT
              echo "doc_count=0" >> $GITHUB_OUTPUT
            fi
          else
            echo "word-docs 目錄不存在"
            echo "has_docs=false" >> $GITHUB_OUTPUT
            echo "doc_count=0" >> $GITHUB_OUTPUT
          fi

      - name: 處理Word文檔
        id: process-documents
        if: |
          (github.event.inputs.process_word == 'true' || github.event.inputs.process_word == '' || github.event_name != 'workflow_dispatch') &&
          (steps.check-documents.outputs.has_docs == 'true' || github.event.inputs.force_process == 'true')
        run: |
          echo "=== 開始處理Word文檔 ==="
          
          # 設置Python路徑
          export PYTHONPATH="$(pwd):$(pwd)/scripts:$(pwd)/.github/scripts:$PYTHONPATH"
          
          # 構建處理參數
          PROCESS_ARGS="--word-dir word-docs --output-dir blog --assets-dir assets"
          
          if [ "${{ github.event.inputs.force_process }}" = "true" ]; then
            PROCESS_ARGS="$PROCESS_ARGS --force --process-all"
            echo "啟用強制處理模式"
          fi
          
          if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
            PROCESS_ARGS="$PROCESS_ARGS --debug"
            echo "啟用調試模式"
          fi
          
          # 嘗試使用主處理腳本
          PROCESSING_SUCCESS=false
          
          if [ -f "main.py" ]; then
            echo "嘗試使用主處理腳本: main.py"
            
            if timeout 600 python main.py $PROCESS_ARGS 2>&1; then
              echo "主處理腳本執行成功"
              PROCESSING_SUCCESS=true
            else
              echo "主處理腳本執行失敗或超時"
              PROCESSING_SUCCESS=false
            fi
          elif [ -f "process.py" ]; then
            echo "嘗試使用備用處理腳本: process.py"
            
            if timeout 600 python process.py $PROCESS_ARGS 2>&1; then
              echo "備用處理腳本執行成功"
              PROCESSING_SUCCESS=true
            else
              echo "備用處理腳本執行失敗"
              PROCESSING_SUCCESS=false
            fi
          else
            echo "未找到主要處理腳本，使用內建處理邏輯"
          fi
          
          # 改進的內建智能處理邏輯
          if [ "$PROCESSING_SUCCESS" = "false" ]; then
            echo "執行改進的內建Word文檔處理邏輯..."
            
            python3 << 'EOF'
          import os
          import json
          import re
          from pathlib import Path
          from datetime import datetime
          
          def parse_filename_advanced(filename):
              """改進的文件名解析，正確識別系列文章"""
              
              # 移除文件擴展名
              name_without_ext = os.path.splitext(filename)[0]
              
              # 系列文章格式: YYYY-MM-DD-系列名稱EP數字-副標題
              series_pattern = r'^(\d{4}-\d{2}-\d{2})-(.+?)EP(\d+)-(.+)$'
              
              # 普通文章格式: YYYY-MM-DD-標題
              normal_pattern = r'^(\d{4}-\d{2}-\d{2})-(.+)$'
              
              print(f"解析文件名: {name_without_ext}")
              
              # 嘗試匹配系列文章格式
              series_match = re.match(series_pattern, name_without_ext)
              if series_match:
                  date_str, series_name, episode_str, subtitle = series_match.groups()
                  print(f"識別為系列文章 - 系列: {series_name}, 集數: {episode_str}, 副標題: {subtitle}")
                  return {
                      'date': date_str,
                      'is_series': True,
                      'series_name': series_name,
                      'episode': int(episode_str),
                      'subtitle': subtitle,
                      'title': f"{series_name}EP{episode_str}-{subtitle}"
                  }
              
              # 嘗試匹配普通文章格式
              normal_match = re.match(normal_pattern, name_without_ext)
              if normal_match:
                  date_str, title = normal_match.groups()
                  print(f"識別為普通文章 - 標題: {title}")
                  return {
                      'date': date_str,
                      'is_series': False,
                      'title': title
                  }
              
              print(f"無法解析文件名格式: {name_without_ext}")
              return None
          
          def should_process_file(file_date_str, force_process=False):
              """檢查是否應該處理該文件（日期檢查）"""
              if force_process:
                  return True
              
              try:
                  file_date = datetime.strptime(file_date_str, '%Y-%m-%d').date()
                  current_date = datetime.now().date()
                  should_process = file_date <= current_date
                  
                  if not should_process:
                      print(f"跳過未來日期文件: {file_date_str} (當前日期: {current_date})")
                  
                  return should_process
              except ValueError:
                  print(f"無效日期格式: {file_date_str}")
                  return False
          
          def get_series_mapping():
              """獲取系列名稱映射表"""
              return {
                  "合建分屋": "joint-construction",
                  "合理分配": "tax-allocation", 
                  "稅務規劃": "tax-planning",
                  "會計實務": "accounting-practice",
                  "保險規劃": "insurance-planning",
                  "企業管理": "business-management",
                  "投資理財": "investment-planning"
              }
          
          def extract_theme_keywords(title, is_series=False, series_name=None, subtitle=None):
              """提取主題關鍵詞，用於URL生成"""
              
              # 主題映射表
              theme_mapping = {
                  # 稅務相關
                  '所得稅': 'income-tax',
                  '營業稅': 'business-tax', 
                  '遺產稅': 'estate-tax',
                  '贈與稅': 'gift-tax',
                  '房屋稅': 'house-tax',
                  '地價稅': 'land-tax',
                  '印花稅': 'stamp-tax',
                  '綜合所得稅': 'income-tax',
                  '營所稅': 'corporate-tax',
                  '個人所得稅': 'personal-income-tax',
                  '稅負': 'tax-burden',
                  '稅務': 'tax',
                  '節稅': 'tax-saving',
                  '避稅': 'tax-avoidance',
                  '扣繳': 'withholding',
                  
                  # 保險相關
                  '人壽保險': 'life-insurance',
                  '保險規劃': 'insurance-planning',
                  '保險給付': 'insurance-benefit',
                  '保單': 'insurance-policy',
                  '受益人': 'beneficiary',
                  '要保人': 'policyholder',
                  '被保險人': 'insured',
                  
                  # 會計相關  
                  '會計': 'accounting',
                  '記帳': 'bookkeeping',
                  '財務報表': 'financial-statement',
                  '成本控制': 'cost-control',
                  '審計': 'audit',
                  '帳務': 'bookkeeping',
                  '財務': 'finance',
                  '財報': 'financial-report',
                  
                  # 企業相關
                  '公司設立': 'company-setup',
                  '企業營運': 'business-operation',
                  '投資': 'investment',
                  '理財': 'financial-planning',
                  '營運': 'operation',
                  '管理': 'management',
                  '策略': 'strategy',
                  '優化': 'optimization',
                  
                  # 文檔類型
                  '指南': 'guide',
                  '攻略': 'tips',
                  '解析': 'analysis',
                  '案例': 'case-study',
                  '注意事項': 'considerations',
                  '實務': 'practice',
                  '流程': 'process',
                  '申報': 'filing',
                  '規劃': 'planning',
                  '錯誤': 'errors',
                  '常見': 'common'
              }
              
              keywords = []
              
              if is_series:
                  # 系列文章：從副標題提取關鍵詞
                  text_to_analyze = subtitle or ""
                  print(f"系列文章關鍵詞分析文本: {text_to_analyze}")
              else:
                  # 普通文章：從整個標題提取關鍵詞
                  text_to_analyze = title
                  print(f"普通文章關鍵詞分析文本: {text_to_analyze}")
              
              # 按詞長度排序，優先匹配較長的專業詞彙
              matched_terms = []
              for zh_term, en_term in theme_mapping.items():
                  if zh_term in text_to_analyze:
                      matched_terms.append((len(zh_term), zh_term, en_term))
              
              # 按詞長度降序排序
              matched_terms.sort(reverse=True)
              
              # 選擇前3個最重要的關鍵詞
              for _, zh_term, en_term in matched_terms[:3]:
                  if en_term not in keywords:
                      keywords.append(en_term)
                      print(f"匹配關鍵詞: {zh_term} -> {en_term}")
              
              # 如果關鍵詞不足，添加通用關鍵詞
              if len(keywords) < 2:
                  if any(tax_term in text_to_analyze for tax_term in ['稅', '報稅', '扣繳', '稅務']):
                      if 'tax' not in keywords:
                          keywords.append('tax')
                  elif any(acc_term in text_to_analyze for acc_term in ['會計', '帳務', '財務', '財報']):
                      if 'accounting' not in keywords:
                          keywords.append('accounting')
                  elif any(ins_term in text_to_analyze for ins_term in ['保險', '保單']):
                      if 'insurance' not in keywords:
                          keywords.append('insurance')
                  else:
                      if 'business' not in keywords:
                          keywords.append('business')
              
              return keywords[:3]  # 限制最多3個關鍵詞
          
          def generate_semantic_url(file_info):
              """生成語義化URL"""
              
              date_str = file_info['date']
              is_series = file_info.get('is_series', False)
              
              url_parts = [date_str]
              
              if is_series:
                  # 系列文章URL格式: 日期-系列名稱-ep集數-主題關鍵詞
                  series_name = file_info['series_name']
                  episode = file_info['episode']
                  subtitle = file_info.get('subtitle', '')
                  
                  # 獲取系列名稱映射
                  series_mapping = get_series_mapping()
                  series_slug = series_mapping.get(series_name, series_name.lower().replace(' ', '-'))
                  url_parts.append(series_slug)
                  
                  # 添加集數
                  url_parts.append(f"ep{episode}")
                  
                  # 從副標題提取主題關鍵詞
                  theme_keywords = extract_theme_keywords(file_info['title'], True, series_name, subtitle)
                  url_parts.extend(theme_keywords[:2])  # 最多2個主題關鍵詞
                  
                  print(f"系列文章URL組件: {url_parts}")
              else:
                  # 普通文章URL格式: 日期-主題關鍵詞
                  title = file_info['title']
                  theme_keywords = extract_theme_keywords(title, False)
                  url_parts.extend(theme_keywords)
                  
                  print(f"普通文章URL組件: {url_parts}")
              
              # 組合URL
              url = '-'.join(url_parts)
              
              # 確保URL長度合理（小於80字符）
              if len(url) > 80:
                  if is_series:
                      # 保留日期、系列名稱、集數和一個關鍵詞
                      url = '-'.join([date_str, url_parts[1], url_parts[2], url_parts[3] if len(url_parts) > 3 else ''])
                  else:
                      # 保留日期和前兩個關鍵詞
                      url = '-'.join([date_str] + url_parts[1:3])
              
              print(f"生成的URL: {url}")
              return url
          
          def determine_category_from_content(title):
              """根據內容判斷分類"""
              title_lower = title.lower()
              
              if any(term in title for term in ['稅', '報稅', '所得稅', '營業稅', '遺產稅', '贈與稅', '稅務', '稅負']):
                  return 'tax', '稅務相關'
              elif any(term in title for term in ['保險', '保單', '受益人', '要保人']):
                  return 'insurance', '保險規劃'
              elif any(term in title for term in ['會計', '帳務', '財務', '財報', '審計', '記帳']):
                  return 'accounting', '會計實務'
              else:
                  return 'business', '企業服務'
          
          def generate_tags_from_content(title, is_series=False, subtitle=None):
              """根據內容生成標籤"""
              text_to_analyze = subtitle if is_series and subtitle else title
              
              tags = []
              
              # 常見標籤映射
              tag_mapping = {
                  '規劃': 'planning',
                  '實務': 'practice', 
                  '策略': 'strategy',
                  '優化': 'optimization',
                  '分析': 'analysis',
                  '指南': 'guide',
                  '案例': 'case-study',
                  '申報': 'filing',
                  '注意事項': 'considerations',
                  '錯誤': 'errors',
                  '常見': 'common'
              }
              
              for zh_tag, en_tag in tag_mapping.items():
                  if zh_tag in text_to_analyze:
                      tag_name = zh_tag
                      tags.append({"slug": en_tag, "name": tag_name})
              
              # 確保至少有一個標籤
              if not tags:
                  tags.append({"slug": "business", "name": "企業服務"})
              
              return tags[:3]  # 最多3個標籤
          
          def process_word_documents():
              """處理Word文檔並生成HTML"""
              word_dir = Path('word-docs')
              blog_dir = Path('blog')
              blog_dir.mkdir(exist_ok=True)
              
              processed_count = 0
              processed_files = []
              force_process = "${{ github.event.inputs.force_process }}" == "true"
              
              if not word_dir.exists():
                  print("word-docs 目錄不存在")
                  return 0, []
              
              print(f"強制處理模式: {force_process}")
              
              # 處理所有Word文檔
              for doc_file in word_dir.glob('*.docx'):
                  if doc_file.name.startswith('~$'):
                      continue
                  
                  try:
                      print(f"\n處理文檔: {doc_file.name}")
                      
                      # 解析文件名
                      file_info = parse_filename_advanced(doc_file.name)
                      if not file_info:
                          print(f"跳過無法解析的文件: {doc_file.name}")
                          continue
                      
                      # 檢查日期（除非強制處理）
                      if not should_process_file(file_info['date'], force_process):
                          continue
                      
                      # 生成語義化URL
                      url_slug = generate_semantic_url(file_info)
                      html_filename = f'{url_slug}.html'
                      html_path = blog_dir / html_filename
                      
                      # 檢查文件是否已存在
                      if html_path.exists() and not force_process:
                          print(f"HTML文件已存在: {html_filename}")
                          processed_files.append(str(doc_file))
                          continue
                      
                      # 判斷分類
                      category, category_name = determine_category_from_content(file_info['title'])
                      
                      # 生成標籤
                      tags = generate_tags_from_content(
                          file_info['title'], 
                          file_info.get('is_series', False), 
                          file_info.get('subtitle')
                      )
                      
                      # 構建標籤HTML
                      tags_html = []
                      for tag in tags:
                          tags_html.append(f'<a class="article-tag" href="/blog.html?tag={tag["slug"]}">{tag["name"]}</a>')
                      tags_html_str = '\n          '.join(tags_html) if tags_html else ''
                      
                      # 構建系列信息HTML（如果是系列文章）
                      series_info_html = ''
                      series_meta_html = ''
                      
                      if file_info.get('is_series', False):
                          series_name = file_info['series_name']
                          episode = file_info['episode']
                          series_mapping = get_series_mapping()
                          series_slug = series_mapping.get(series_name, series_name.lower().replace(' ', '-'))
                          
                          series_info_html = f'''<div class="series-info">
          <span class="series-badge">系列文章</span>
          <span class="series-name">{series_name}</span>
          <span class="series-episode">第 {episode} 集</span>
          </div>'''
                          
                          series_meta_html = f'''<meta name="series-name" content="{series_name}"/>
          <meta name="series-episode" content="{episode}"/>
          <meta name="series-slug" content="{series_slug}"/>'''
                      
                      # 創建完整的HTML內容
                      html_content = f'''<!DOCTYPE html>
          <html lang="zh-TW">
          <head>
          <meta charset="utf-8"/>
          <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
          <meta name="description" content="{file_info['title']} - 霍爾果斯會計師事務所專業服務，提供{category_name}相關諮詢"/>
          <meta name="keywords" content="{category_name}, 霍爾果斯, 會計師, 稅務, 保險, 企業服務"/>
          <meta name="date" content="{file_info['date']}"/>
          <meta name="main-category" content="{category_name}"/>
          <meta name="main-category-code" content="{category}"/>
          <meta name="original-filename" content="{doc_file.name}"/>
          {series_meta_html}
          <title>{file_info['title']} | 霍爾果斯會計師事務所</title>
          <link rel="canonical" href="https://www.horgoscpa.com/blog/{html_filename}"/>
          
          <!-- Favicon -->
          <link rel="icon" type="image/x-icon" href="/favicon.ico">
          
          <!-- Material Symbols 圖示庫 -->
          <link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" rel="stylesheet">
          
          <!-- 引用全站共用樣式 -->
          <link href="/assets/css/common.css" rel="stylesheet">
          <link href="/assets/css/navbar.css" rel="stylesheet">
          <link href="/assets/css/footer.css" rel="stylesheet">
          <link href="/assets/css/blog-article-modern.css" rel="stylesheet"/>
          
          <!-- 系列文章樣式 -->
          <style>
          .series-info {{
              display: flex;
              align-items: center;
              gap: 1rem;
              margin-bottom: 1.5rem;
              padding: 1rem;
              background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
              border-radius: 8px;
              color: white;
          }}
          
          .series-badge {{
              background: rgba(255, 255, 255, 0.2);
              padding: 0.3rem 0.8rem;
              border-radius: 20px;
              font-size: 0.85rem;
              font-weight: 500;
          }}
          
          .series-name {{
              font-weight: 600;
              flex-grow: 1;
          }}
          
          .series-episode {{
              background: rgba(255, 255, 255, 0.2);
              padding: 0.3rem 0.8rem;
              border-radius: 20px;
              font-size: 0.85rem;
          }}
          </style>
          </head>
          <body>
          <article class="article-card">
          <div class="article-meta">
          <div class="article-date">
          <span class="material-symbols-rounded">calendar_month</span>
          {file_info['date']}
          </div>
          <div class="article-category">
          <span class="material-symbols-rounded">sell</span>
          {category_name}
          </div>
          </div>
          
          {series_info_html}
          
          <h1 class="article-title">{file_info['title']}</h1>
          <div class="article-body">
          <p>本文檔正在處理中，完整內容即將推出。我們的專業團隊正在為您準備最詳細的{category_name}指導。</p>
          <p>如需立即諮詢相關服務，請聯繫霍爾果斯會計師事務所，我們將為您提供專業的解決方案。</p>
          <div class="contact-info">
          <h3>聯繫我們</h3>
          <p>電話：(02) 1234-5678</p>
          <p>Email：info@horgoscpa.com</p>
          </div>
          </div>
          <div class="article-footer">
          <div class="article-tags">
          {tags_html_str}
          </div>
          </div>
          </article>
          </body>
          </html>'''
                      
                      # 寫入HTML文件
                      with open(html_path, 'w', encoding='utf-8') as f:
                          f.write(html_content)
                      
                      print(f"生成HTML: {doc_file.name} → {html_filename}")
                      processed_count += 1
                      processed_files.append(str(doc_file))
                      
                  except Exception as e:
                      print(f"處理文件 {doc_file.name} 時出錯: {e}")
                      import traceback
                      traceback.print_exc()
                      continue
              
              return processed_count, processed_files
          
          try:
              print("開始改進的Word文檔處理...")
              processed_count, processed_files = process_word_documents()
              
              print(f"\n處理完成，共處理 {processed_count} 個文檔")
              
              # 更新處理記錄
              processed_data = {'files': processed_files}
              processed_files_path = Path('assets/data/processed_files.json')
              
              # 讀取並合併現有記錄
              if processed_files_path.exists():
                  try:
                      with open(processed_files_path, 'r', encoding='utf-8') as f:
                          existing_data = json.load(f)
                          if 'files' in existing_data:
                              all_files = list(set(existing_data['files'] + processed_files))
                              processed_data = {'files': all_files}
                  except Exception as e:
                      print(f"讀取現有處理記錄失敗: {e}")
              
              # 保存處理記錄
              with open(processed_files_path, 'w', encoding='utf-8') as f:
                  json.dump(processed_data, f, ensure_ascii=False, indent=2)
              
              print("Word文檔處理完成")
              
          except Exception as e:
              print(f"Word文檔處理失敗: {e}")
              import traceback
              traceback.print_exc()
          EOF
          fi
          
          # 檢查處理結果
          HTML_COUNT=$(find blog -name "*.html" 2>/dev/null | wc -l)
          
          if [ "$HTML_COUNT" -gt 0 ]; then
            echo "docs_processed=true" >> $GITHUB_OUTPUT
            echo "html_count=$HTML_COUNT" >> $GITHUB_OUTPUT
            echo "✓ 成功處理，共生成 $HTML_COUNT 個HTML文件"
          else
            echo "docs_processed=false" >> $GITHUB_OUTPUT
            echo "html_count=0" >> $GITHUB_OUTPUT
            echo "⚠ 警告：沒有生成HTML文件"
          fi

      - name: 更新影片數據
        id: update-video-data
        run: |
          echo "=== 更新影片數據 ==="
          
          if [ -f ".github/scripts/update_videos.py" ]; then
            echo "執行影片數據更新腳本..."
            export PYTHONPATH="$(pwd):$(pwd)/scripts:$PYTHONPATH"
            
            if python .github/scripts/update_videos.py; then
              echo "影片數據更新成功"
            else
              echo "影片數據更新失敗，使用基本方案"
            fi
          else
            echo "創建基本影片數據..."
          fi
          
          # 確保影片數據文件存在
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          videos_file = Path('assets/data/videos.json')
          if not videos_file.exists():
              videos_data = {
                  "videos": [],
                  "pagination": {
                      "total": 0,
                      "totalPages": 1,
                      "itemsPerPage": 6
                  }
              }
              with open(videos_file, 'w', encoding='utf-8') as f:
                  json.dump(videos_data, f, ensure_ascii=False, indent=2)
              print("創建基本影片數據文件")
          else:
              print("影片數據文件已存在")
          EOF
          
          echo "video_updated=true" >> $GITHUB_OUTPUT

      - name: 生成JSON數據
        id: generate-json-data
        if: |
          steps.process-documents.outputs.docs_processed == 'true' || 
          github.event.inputs.update_json == 'true' || 
          github.event.inputs.update_json == '' ||
          github.event_name != 'workflow_dispatch'
        run: |
          echo "=== 生成JSON數據 ==="
          
          export PYTHONPATH="$(pwd):$(pwd)/scripts:$(pwd)/.github/scripts:$PYTHONPATH"
          
          # 嘗試使用專用JSON生成器
          if [ -f ".github/scripts/update_blog_json.py" ]; then
            echo "使用專用JSON生成器..."
            if python .github/scripts/update_blog_json.py; then
              echo "專用JSON生成器執行成功"
            else
              echo "專用JSON生成器執行失敗，使用內建方案"
            fi
          elif [ -f "scripts/json_generator.py" ]; then
            echo "使用核心JSON生成器..."
            python3 << 'EOF'
          import sys
          sys.path.insert(0, './scripts')
          
          try:
              from json_generator import JsonGenerator
              generator = JsonGenerator('assets/data')
              result = generator.generate_all_json()
              print('核心JSON生成器執行成功')
          except Exception as e:
              print(f'核心JSON生成器執行失敗: {e}')
          EOF
          else
            echo "使用內建JSON生成邏輯..."
          fi
          
          # 改進的內建JSON生成邏輯
          python3 << 'EOF'
          import json
          import re
          from pathlib import Path
          from datetime import datetime
          from collections import defaultdict
          
          def extract_series_info_from_html(content):
              """從HTML內容提取系列信息"""
              series_name_match = re.search(r'<meta name="series-name" content="([^"]+)"', content)
              series_episode_match = re.search(r'<meta name="series-episode" content="([^"]+)"', content)
              series_slug_match = re.search(r'<meta name="series-slug" content="([^"]+)"', content)
              
              if series_name_match and series_episode_match:
                  return {
                      'is_series': True,
                      'series_name': series_name_match.group(1),
                      'series_episode': int(series_episode_match.group(1)),
                      'series_slug': series_slug_match.group(1) if series_slug_match else ''
                  }
              return {'is_series': False}
          
          def generate_blog_data():
              """生成完整的博客數據"""
              
              blog_dir = Path('blog')
              posts = []
              
              if not blog_dir.exists():
                  print("blog目錄不存在")
                  return
              
              # 掃描所有HTML文件
              html_files = list(blog_dir.glob('*.html'))
              print(f"發現 {len(html_files)} 個HTML文件")
              
              for html_file in html_files:
                  try:
                      # 從HTML文件提取信息
                      with open(html_file, 'r', encoding='utf-8') as f:
                          content = f.read()
                      
                      # 使用正則表達式提取meta信息
                      title_match = re.search(r'<title>([^|]+)', content)
                      date_match = re.search(r'<meta name="date" content="([^"]+)"', content)
                      desc_match = re.search(r'<meta name="description" content="([^"]+)"', content)
                      category_match = re.search(r'<meta name="main-category-code" content="([^"]+)"', content)
                      category_name_match = re.search(r'<meta name="main-category" content="([^"]+)"', content)
                      
                      # 提取基本信息
                      title = title_match.group(1).strip() if title_match else html_file.stem
                      date_str = date_match.group(1) if date_match else datetime.now().strftime('%Y-%m-%d')
                      description = desc_match.group(1) if desc_match else f"{title} 的詳細說明"
                      category = category_match.group(1) if category_match else 'business'
                      category_name = category_name_match.group(1) if category_name_match else '企業服務'
                      
                      # 提取系列信息
                      series_info = extract_series_info_from_html(content)
                      
                      # 從HTML中提取標籤
                      tags = []
                      tag_matches = re.findall(r'<a class="article-tag" href="[^"]*tag=([^"]+)"[^>]*>([^<]+)</a>', content)
                      for tag_slug, tag_name in tag_matches:
                          tags.append({"slug": tag_slug, "name": tag_name})
                      
                      # 構建文章數據
                      post = {
                          "title": title,
                          "url": f"/blog/{html_file.name}",
                          "date": date_str,
                          "summary": description,
                          "category": category,
                          "category_name": category_name,
                          "tags": tags,
                          "image": "/assets/images/blog/default.jpg",
                          "is_series": series_info['is_series']
                      }
                      
                      # 添加系列相關信息
                      if series_info['is_series']:
                          post["series_name"] = series_info['series_name']
                          post["series_slug"] = series_info['series_slug']
                          post["episode"] = series_info['series_episode']
                      
                      posts.append(post)
                      
                  except Exception as e:
                      print(f"處理HTML文件 {html_file} 時出錯: {e}")
              
              # 按日期排序
              posts.sort(key=lambda x: x['date'], reverse=True)
              
              # 統計分類和標籤
              category_counts = defaultdict(int)
              tag_counts = defaultdict(int)
              
              for post in posts:
                  category_counts[post['category']] += 1
                  for tag in post['tags']:
                      tag_counts[tag['slug']] += 1
              
              # 生成分類數據
              categories = [
                  {"slug": "tax", "name": "稅務相關", "count": category_counts.get('tax', 0)},
                  {"slug": "insurance", "name": "保險規劃", "count": category_counts.get('insurance', 0)},
                  {"slug": "accounting", "name": "會計實務", "count": category_counts.get('accounting', 0)},
                  {"slug": "business", "name": "企業服務", "count": category_counts.get('business', 0)}
              ]
              
              # 生成標籤數據
              tags_data = []
              for tag_slug, count in tag_counts.items():
                  tag_name = tag_slug.replace('-', ' ').title()
                  tags_data.append({"slug": tag_slug, "name": tag_name, "count": count})
              
              # 組織系列文章
              series_dict = defaultdict(list)
              for post in posts:
                  if post.get('is_series', False) and post.get('series_slug'):
                      series_dict[post['series_slug']].append(post)
              
              # 生成系列信息
              series_info = {}
              series_list = []
              
              for series_slug, series_posts in series_dict.items():
                  # 按集數排序
                  series_posts.sort(key=lambda x: x.get('episode', 0))
                  
                  series_name = series_posts[0].get('series_name', series_slug) if series_posts else series_slug
                  
                  series_data = {
                      "name": series_name,
                      "slug": series_slug,
                      "posts": series_posts,
                      "count": len(series_posts),
                      "latest": series_posts[0] if series_posts else None,
                      "first_post_date": series_posts[-1]["date"] if series_posts else None,
                      "latest_post_date": series_posts[0]["date"] if series_posts else None
                  }
                  
                  series_info[series_slug] = series_data
                  series_list.append(series_data)
              
              # 按最新文章日期排序
              series_list.sort(key=lambda x: x["latest_post_date"], reverse=True)
              
              # 生成完整博客數據
              blog_data = {
                  "posts": posts,
                  "pagination": {
                      "total_posts": len(posts),
                      "total_pages": max(1, (len(posts) + 9) // 10),
                      "items_per_page": 10
                  },
                  "categories": categories,
                  "tags": tags_data,
                  "series": series_info,
                  "series_list": series_list,
                  "generated_time": datetime.now().isoformat()
              }
              
              # 保存各種JSON文件
              assets_data = Path('assets/data')
              assets_data.mkdir(parents=True, exist_ok=True)
              
              json_files = {
                  'blog_posts.json': {"posts": posts},
                  'blog-posts.json': {"posts": posts},
                  'blog-index.json': blog_data,
                  'latest-posts.json': posts[:3],
                  'series.json': {"series": series_info, "series_list": series_list},
                  'categories.json': {"categories": categories},
                  'tags.json': {"tags": tags_data}
              }
              
              for filename, data in json_files.items():
                  file_path = assets_data / filename
                  with open(file_path, 'w', encoding='utf-8') as f:
                      json.dump(data, f, ensure_ascii=False, indent=2)
                  print(f"生成JSON文件: {filename}")
              
              print(f"JSON數據生成完成，共處理 {len(posts)} 篇文章")
              if series_list:
                  print(f"包含 {len(series_list)} 個系列文章")
                  for series in series_list:
                      print(f"  - {series['name']}: {series['count']} 篇文章")
              
              return len(posts)
          
          try:
              post_count = generate_blog_data()
              print(f"JSON數據生成成功，共 {post_count} 篇文章")
          except Exception as e:
              print(f"JSON數據生成失敗: {e}")
              import traceback
              traceback.print_exc()
          EOF
          
          echo "json_updated=true" >> $GITHUB_OUTPUT

      - name: 生成網站地圖
        id: generate-sitemap
        if: steps.generate-json-data.outputs.json_updated == 'true'
        run: |
          echo "=== 生成網站地圖 ==="
          
          if [ -f ".github/scripts/generate_sitemap.py" ]; then
            echo "使用專用網站地圖生成器..."
            export PYTHONPATH="$(pwd):$(pwd)/scripts:$PYTHONPATH"
            
            if python .github/scripts/generate_sitemap.py; then
              echo "專用網站地圖生成器執行成功"
            else
              echo "專用網站地圖生成器執行失敗，使用內建方案"
            fi
          else
            echo "使用內建網站地圖生成邏輯..."
          fi
          
          # 內建網站地圖生成
          python3 << 'EOF'
          from datetime import datetime
          from pathlib import Path
          import json
          
          def generate_sitemap():
              """生成網站地圖"""
              
              today = datetime.now().strftime('%Y-%m-%d')
              
              # 基本sitemap結構
              sitemap_content = f'''<?xml version="1.0" encoding="UTF-8"?>
          <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
            <url>
              <loc>https://www.horgoscpa.com/</loc>
              <lastmod>{today}</lastmod>
              <changefreq>daily</changefreq>
              <priority>1.0</priority>
            </url>
            <url>
              <loc>https://www.horgoscpa.com/blog.html</loc>
              <lastmod>{today}</lastmod>
              <changefreq>daily</changefreq>
              <priority>0.9</priority>
            </url>
            <url>
              <loc>https://www.horgoscpa.com/services.html</loc>
              <lastmod>{today}</lastmod>
              <changefreq>monthly</changefreq>
              <priority>0.9</priority>
            </url>
            <url>
              <loc>https://www.horgoscpa.com/contact.html</loc>
              <lastmod>{today}</lastmod>
              <changefreq>monthly</changefreq>
              <priority>0.8</priority>
            </url>'''
              
              # 添加博客文章
              blog_dir = Path('blog')
              if blog_dir.exists():
                  for html_file in blog_dir.glob('*.html'):
                      sitemap_content += f'''
            <url>
              <loc>https://www.horgoscpa.com/blog/{html_file.name}</loc>
              <lastmod>{today}</lastmod>
              <changefreq>weekly</changefreq>
              <priority>0.8</priority>
            </url>'''
              
              sitemap_content += '''
          </urlset>'''
              
              # 保存sitemap
              with open('sitemap.xml', 'w', encoding='utf-8') as f:
                  f.write(sitemap_content)
              
              print('網站地圖生成完成')
              
              # 統計信息
              url_count = sitemap_content.count('<url>')
              print(f'包含 {url_count} 個URL')
              
              return True
          
          try:
              generate_sitemap()
          except Exception as e:
              print(f'網站地圖生成失敗: {e}')
              import traceback
              traceback.print_exc()
          EOF
          
          echo "sitemap_generated=true" >> $GITHUB_OUTPUT

      - name: 移動已處理文檔
        id: move-processed-files
        if: steps.process-documents.outputs.docs_processed == 'true'
        run: |
          echo "=== 移動已處理的Word文檔 ==="
          
          # 確保目錄存在
          mkdir -p word-docs/processed
          
          if [ -f ".github/scripts/move_processed_files.py" ]; then
            echo "使用專用文件移動腳本..."
            export PYTHONPATH="$(pwd):$(pwd)/scripts:$PYTHONPATH"
            
            if python .github/scripts/move_processed_files.py; then
              echo "專用文件移動腳本執行成功"
            else
              echo "專用文件移動腳本執行失敗，使用內建方案"
            fi
          else
            echo "使用內建文件移動邏輯..."
          fi
          
          # 內建文件移動邏輯
          python3 << 'EOF'
          import json
          import shutil
          from pathlib import Path
          
          def move_processed_files():
              """移動已處理的Word文檔"""
              
              try:
                  # 讀取已處理文件記錄
                  processed_files_path = Path('assets/data/processed_files.json')
                  processed_files = {'files': []}
                  
                  if processed_files_path.exists():
                      with open(processed_files_path, 'r', encoding='utf-8') as f:
                          processed_files = json.load(f)
                  
                  if not processed_files.get('files'):
                      print('沒有已處理的文件需要移動')
                      return 0
                  
                  # 移動文件
                  word_dir = Path('word-docs')
                  processed_dir = Path('word-docs/processed')
                  processed_dir.mkdir(exist_ok=True)
                  
                  moved_count = 0
                  
                  for file_path_str in processed_files['files']:
                      file_path = Path(file_path_str)
                      
                      if file_path.exists() and file_path.parent == word_dir:
                          dest_path = processed_dir / file_path.name
                          
                          try:
                              if not dest_path.exists():
                                  shutil.move(str(file_path), str(dest_path))
                                  print(f'移動文件: {file_path.name}')
                                  moved_count += 1
                              else:
                                  # 如果目標已存在，刪除源文件
                                  file_path.unlink()
                                  print(f'刪除重複文件: {file_path.name}')
                                  moved_count += 1
                          except Exception as e:
                              print(f'移動文件失敗 {file_path.name}: {e}')
                  
                  print(f'共移動 {moved_count} 個文件')
                  return moved_count
                  
              except Exception as e:
                  print(f'移動文件過程出錯: {e}')
                  return 0
          
          moved_count = move_processed_files()
          print(f'文件移動完成，共處理 {moved_count} 個文件')
          EOF
          
          echo "files_moved=true" >> $GITHUB_OUTPUT

      - name: 提交所有更改
        if: |
          steps.process-documents.outputs.docs_processed == 'true' || 
          steps.generate-json-data.outputs.json_updated == 'true' ||
          steps.generate-sitemap.outputs.sitemap_generated == 'true' ||
          steps.move-processed-files.outputs.files_moved == 'true'
        run: |
          echo "=== 提交所有更改 ==="
          
          # 檢查Git狀態
          echo "檢查Git狀態..."
          git status --porcelain
          
          # 添加所有更改
          git add -A
          
          # 檢查是否有更改需要提交
          if git diff --cached --quiet; then
            echo "沒有更改需要提交"
          else
            # 構建提交信息
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M:%S')
            COMMIT_MSG="自動化處理更新 [$TIMESTAMP]"
            
            # 添加詳細信息
            CHANGES=()
            
            if [ "${{ steps.process-documents.outputs.docs_processed }}" = "true" ]; then
              HTML_COUNT="${{ steps.process-documents.outputs.html_count }}"
              CHANGES+=("處理Word文檔(${HTML_COUNT}個)")
            fi
            
            if [ "${{ steps.generate-json-data.outputs.json_updated }}" = "true" ]; then
              CHANGES+=("更新JSON數據")
            fi
            
            if [ "${{ steps.generate-sitemap.outputs.sitemap_generated }}" = "true" ]; then
              CHANGES+=("生成網站地圖")
            fi
            
            if [ "${{ steps.move-processed-files.outputs.files_moved }}" = "true" ]; then
              CHANGES+=("移動已處理文檔")
            fi
            
            # 組合提交信息
            if [ ${#CHANGES[@]} -gt 0 ]; then
              IFS=', '
              COMMIT_MSG="${COMMIT_MSG} - ${CHANGES[*]}"
            fi
            
            echo "提交信息: $COMMIT_MSG"
            
            # 提交更改
            git commit -m "$COMMIT_MSG"
            
            # 推送更改（帶重試機制）
            echo "推送更改到遠程倉庫..."
            MAX_RETRIES=3
            RETRY_COUNT=0
            
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if git push origin ${{ github.ref_name }}; then
                echo "✓ 成功推送更改"
                break
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                echo "✗ 推送失敗，第 $RETRY_COUNT 次重試..."
                
                if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
                  echo "推送失敗，已達最大重試次數"
                  exit 1
                else
                  echo "等待5秒後重試..."
                  sleep 5
                  
                  # 嘗試拉取最新更改
                  git pull --rebase origin ${{ github.ref_name }} || true
                fi
              fi
            done
          fi

      - name: 輸出執行摘要
        if: always()
        run: |
          echo "=================================================="
          echo "           自動化處理執行摘要"
          echo "=================================================="
          echo "執行時間: $(date +'%Y-%m-%d %H:%M:%S')"
          echo "觸發方式: ${{ github.event_name }}"
          echo "執行分支: ${{ github.ref_name }}"
          
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo ""
            echo "手動觸發參數:"
            echo "  ├─ 處理Word文檔: ${{ github.event.inputs.process_word || 'true' }}"
            echo "  ├─ 更新JSON文件: ${{ github.event.inputs.update_json || 'true' }}"
            echo "  ├─ 強制處理: ${{ github.event.inputs.force_process || 'false' }}"
            echo "  └─ 調試模式: ${{ github.event.inputs.debug_mode || 'false' }}"
          fi
          
          echo ""
          echo "處理結果:"
          echo "  ├─ 文檔檢查: ${{ steps.check-documents.outputs.has_docs == 'true' && '✓' || '✗' }} (發現 ${{ steps.check-documents.outputs.doc_count || '0' }} 個)"
          echo "  ├─ 文檔處理: ${{ steps.process-documents.outputs.docs_processed == 'true' && '✓' || '✗' }} (生成 ${{ steps.process-documents.outputs.html_count || '0' }} 個HTML)"
          echo "  ├─ 影片數據: ${{ steps.update-video-data.outputs.video_updated == 'true' && '✓' || '✗' }}"
          echo "  ├─ JSON生成: ${{ steps.generate-json-data.outputs.json_updated == 'true' && '✓' || '✗' }}"
          echo "  ├─ 網站地圖: ${{ steps.generate-sitemap.outputs.sitemap_generated == 'true' && '✓' || '✗' }}"
          echo "  └─ 文件移動: ${{ steps.move-processed-files.outputs.files_moved == 'true' && '✓' || '✗' }}"
          
          echo ""
          echo "文件統計:"
          echo "  ├─ HTML文件: $(find blog -name "*.html" 2>/dev/null | wc -l) 個"
          echo "  ├─ JSON文件: $(find assets/data -name "*.json" 2>/dev/null | wc -l) 個"
          echo "  ├─ 待處理Word文檔: $(find word-docs -maxdepth 1 -name "*.docx" ! -name "~$*" 2>/dev/null | wc -l) 個"
          echo "  └─ 已處理Word文檔: $(find word-docs/processed -name "*.docx" 2>/dev/null | wc -l) 個"
          
          echo ""
          echo "系統狀態:"
          echo "  ├─ 磁盤使用: $(df -h . | tail -1 | awk '{print $5}') (已使用)"
          echo "  ├─ 內存使用: $(free -h | grep Mem: | awk '{print $3"/"$2}')"
          echo "  └─ 執行時長: $SECONDS 秒"
          
          echo ""
          echo "URL生成示例:"
          if [ -d "blog" ]; then
            echo "  最新生成的文章URL:"
            find blog -name "*.html" -type f | head -5 | while read file; do
              echo "    - $(basename "$file")"
            done
          fi
          
          echo ""
          echo "系列文章統計:"
          python3 << 'EOF'
          import json
          from pathlib import Path
          
          try:
              series_file = Path('assets/data/series.json')
              if series_file.exists():
                  with open(series_file, 'r', encoding='utf-8') as f:
                      series_data = json.load(f)
                  
                  series_list = series_data.get('series_list', [])
                  if series_list:
                      print(f"  發現 {len(series_list)} 個系列:")
                      for series in series_list[:5]:  # 顯示前5個系列
                          print(f"    - {series['name']}: {series['count']} 篇文章")
                  else:
                      print("  目前沒有系列文章")
              else:
                  print("  系列數據文件不存在")
          except Exception as e:
              print(f"  讀取系列數據失敗: {e}")
          EOF
          
          echo ""
          echo "=================================================="

      - name: 清理臨時文件
        if: always()
        run: |
          echo "=== 清理臨時文件 ==="
          
          # 清理Python緩存
          find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
          find . -name "*.pyc" -delete 2>/dev/null || true
          find . -name "*.pyo" -delete 2>/dev/null || true
          
          # 清理Word臨時文件
          find . -name "~$*.docx" -delete 2>/dev/null || true
          find . -name "~$*.doc" -delete 2>/dev/null || true
          
          # 清理系統臨時文件
          find /tmp -name "tmp*" -user $(whoami) -delete 2>/dev/null || true
          
          # 清理舊日誌文件（保留最近7天）
          if [ -d "logs" ]; then
            find logs -name "*.log" -mtime +7 -delete 2>/dev/null || true
            echo "清理舊日誌文件完成"
          fi
          
          # 顯示清理後的磁盤使用情況
          echo "清理後磁盤使用情況: $(df -h . | tail -1 | awk '{print $5}')"
          
          echo "臨時文件清理完成"