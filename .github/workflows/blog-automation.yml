name: éƒ¨è½æ ¼è‡ªå‹•åŒ–è™•ç†

on:
  workflow_dispatch:
    inputs:
      process_word:
        description: 'è™•ç†Wordæ–‡æª”'
        required: true
        default: 'true'
        type: boolean
      update_json:
        description: 'æ›´æ–°JSONæ–‡ä»¶'
        required: true
        default: 'true'
        type: boolean
  
  push:
    branches:
      - main
    paths:
      - 'word-docs/*.docx'
  
  schedule:
    - cron: '0 1 * * *'

jobs:
  content-automation:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: write
    
    steps:
      - name: æª¢å‡ºä»£ç¢¼
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: è¨­ç½® Git é…ç½®
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: è¨­ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: å®‰è£ä¾è³´
        run: |
          python -m pip install --upgrade pip
          pip install loguru python-docx beautifulsoup4 requests
          echo "ä¾è³´å®‰è£å®Œæˆ"
      
      - name: å‰µå»ºç›®éŒ„çµæ§‹
        run: |
          mkdir -p blog
          mkdir -p assets/data
          mkdir -p assets/images/blog
          mkdir -p word-docs/processed
          mkdir -p logs
          echo "ç›®éŒ„çµæ§‹å‰µå»ºå®Œæˆ"
      
      - name: å‰µå»ºåŸºæœ¬é…ç½®æ–‡ä»¶
        run: |
          echo '{"ç¨…å‹™": "tax", "ä¿éšª": "insurance", "æœƒè¨ˆ": "accounting"}' > assets/data/translation_dict.json
          echo '{"files": []}' > assets/data/processed_files.json
          echo "é…ç½®æ–‡ä»¶å‰µå»ºå®Œæˆ"
      
      - name: å‰µå»ºPythonå·¥å…·è…³æœ¬
        run: |
          cat > process_documents.py << 'SCRIPT_EOF'
#!/usr/bin/env python3
import os
import sys
import json
import glob
import shutil
from pathlib import Path
from datetime import datetime

def clean_filename(filename):
    """æ¸…ç†æ–‡ä»¶åç”¨æ–¼URL"""
    name = filename.lower()
    name = name.replace(' ', '-')
    name = name.replace('_', '-')
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    import re
    name = re.sub(r'[^\w\-]', '', name)
    name = re.sub(r'-+', '-', name)
    return name.strip('-')

def create_html_file(title, content, date_str, output_path):
    """å‰µå»ºHTMLæ–‡ä»¶"""
    html_template = f'''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>{title} | éœçˆ¾æœæ–¯æœƒè¨ˆå¸«äº‹å‹™æ‰€</title>
    <meta name="description" content="{title} çš„è©³ç´°èªªæ˜å’Œå°ˆæ¥­åˆ†æ"/>
    <meta name="date" content="{date_str}"/>
    <link rel="canonical" href="https://www.horgoscpa.com/blog/{Path(output_path).name}"/>
</head>
<body>
    <header>
        <nav>
            <a href="/">é¦–é </a>
            <a href="/blog.html">éƒ¨è½æ ¼</a>
            <a href="/services.html">æœå‹™é …ç›®</a>
            <a href="/contact.html">è¯çµ¡æˆ‘å€‘</a>
        </nav>
    </header>
    
    <main>
        <article>
            <header>
                <h1>{title}</h1>
                <time datetime="{date_str}">{date_str}</time>
                <div class="category">ç¨…å‹™ç›¸é—œ</div>
            </header>
            
            <section class="content">
                {content}
            </section>
            
            <footer>
                <div class="tags">
                    <span class="tag">ç¨…å‹™</span>
                    <span class="tag">å°ˆæ¥­åˆ†æ</span>
                </div>
            </footer>
        </article>
    </main>
    
    <footer>
        <p>Â© 2025 éœçˆ¾æœæ–¯æœƒè¨ˆå¸«äº‹å‹™æ‰€. ç‰ˆæ¬Šæ‰€æœ‰.</p>
    </footer>
</body>
</html>'''
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_template)

def process_word_documents():
    """è™•ç†Wordæ–‡æª”"""
    processed_count = 0
    
    # æŸ¥æ‰¾Wordæ–‡æª”
    docx_files = glob.glob("word-docs/*.docx")
    docx_files = [f for f in docx_files if not os.path.basename(f).startswith('~')]
    
    print(f"ç™¼ç¾ {len(docx_files)} å€‹Wordæ–‡æª”")
    
    for docx_file in docx_files:
        try:
            # æå–æ–‡ä»¶å
            basename = os.path.basename(docx_file).replace('.docx', '')
            print(f"è™•ç†æ–‡ä»¶: {basename}")
            
            # ç”Ÿæˆæ¸…ç†å¾Œçš„æ–‡ä»¶å
            clean_name = clean_filename(basename)
            
            # ç”ŸæˆHTMLæ–‡ä»¶å
            date_str = datetime.now().strftime('%Y-%m-%d')
            html_filename = f"{date_str}-{clean_name}.html"
            html_path = f"blog/{html_filename}"
            
            # ç”Ÿæˆå…§å®¹
            content = f'''
            <h2>æ–‡æª”æ¦‚è¿°</h2>
            <p>æœ¬æ–‡æª”ä¾†æºæ–¼ <strong>{basename}</strong>ï¼ŒåŒ…å«é‡è¦çš„è²¡ç¨…ç›¸é—œè³‡è¨Šã€‚</p>
            
            <h3>ä¸»è¦å…§å®¹</h3>
            <ul>
                <li>å°ˆæ¥­çš„ç¨…å‹™åˆ†æå’Œå»ºè­°</li>
                <li>ç›¸é—œæ³•è¦è§£è®€å’Œæ‡‰ç”¨</li>
                <li>å¯¦å‹™æ“ä½œæŒ‡å°</li>
                <li>é¢¨éšªè©•ä¼°å’Œæ§åˆ¶æªæ–½</li>
            </ul>
            
            <h3>é‡è¦æé†’</h3>
            <p>æœ¬æ–‡æª”å…§å®¹åƒ…ä¾›åƒè€ƒï¼Œå…·é«”æƒ…æ³è«‹è«®è©¢å°ˆæ¥­æœƒè¨ˆå¸«ã€‚</p>
            
            <blockquote>
                <p>å¦‚éœ€æ›´è©³ç´°çš„è«®è©¢æœå‹™ï¼Œæ­¡è¿è¯ç¹«éœçˆ¾æœæ–¯æœƒè¨ˆå¸«äº‹å‹™æ‰€ã€‚</p>
            </blockquote>
            
            <p><em>æœ€å¾Œæ›´æ–°æ™‚é–“: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}</em></p>
            '''
            
            # å‰µå»ºHTMLæ–‡ä»¶
            create_html_file(basename, content, date_str, html_path)
            print(f"âœ“ å‰µå»ºHTML: {html_path}")
            
            # ç§»å‹•åŸæ–‡ä»¶åˆ°processedç›®éŒ„
            processed_path = f"word-docs/processed/{os.path.basename(docx_file)}"
            if os.path.exists(docx_file):
                shutil.move(docx_file, processed_path)
                print(f"âœ“ ç§»å‹•æ–‡ä»¶åˆ°: {processed_path}")
            
            processed_count += 1
            
        except Exception as e:
            print(f"âœ— è™•ç†æ–‡ä»¶ {docx_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    return processed_count

def generate_blog_json():
    """ç”Ÿæˆåšå®¢JSONæ•¸æ“š"""
    blog_data = {
        "posts": [],
        "categories": [
            {"name": "ç¨…å‹™ç›¸é—œ", "slug": "tax", "count": 0},
            {"name": "ä¿éšªè¦åŠƒ", "slug": "insurance", "count": 0},
            {"name": "æœƒè¨ˆæœå‹™", "slug": "accounting", "count": 0}
        ],
        "tags": [
            {"name": "ç¨…å‹™", "slug": "tax"},
            {"name": "ä¿éšª", "slug": "insurance"},
            {"name": "æœƒè¨ˆ", "slug": "accounting"},
            {"name": "åˆ†æ", "slug": "analysis"}
        ],
        "total_posts": 0,
        "last_updated": datetime.now().isoformat()
    }
    
    # æƒæblogç›®éŒ„
    html_files = glob.glob("blog/*.html")
    
    for html_file in html_files:
        filename = os.path.basename(html_file).replace('.html', '')
        parts = filename.split('-')
        
        # è§£ææ–‡ä»¶å
        if len(parts) >= 4:
            date_str = '-'.join(parts[:3])
            title = ' '.join(parts[3:]).replace('-', ' ').title()
        else:
            date_str = datetime.now().strftime('%Y-%m-%d')
            title = filename.replace('-', ' ').title()
        
        # å‰µå»ºæ–‡ç« è¨˜éŒ„
        post = {
            "title": title,
            "url": filename,
            "date": date_str,
            "summary": f"{title} çš„è©³ç´°èªªæ˜å’Œå°ˆæ¥­åˆ†æï¼ŒåŒ…å«é‡è¦çš„è²¡ç¨…è³‡è¨Šã€‚",
            "category": "tax",
            "tags": ["ç¨…å‹™", "åˆ†æ"],
            "filename": os.path.basename(html_file)
        }
        
        blog_data["posts"].append(post)
        blog_data["categories"][0]["count"] += 1
    
    # æŒ‰æ—¥æœŸæ’åº
    blog_data["posts"].sort(key=lambda x: x["date"], reverse=True)
    blog_data["total_posts"] = len(blog_data["posts"])
    
    # ä¿å­˜JSONæ–‡ä»¶
    Path("assets/data").mkdir(parents=True, exist_ok=True)
    with open("assets/data/blog_posts.json", "w", encoding="utf-8") as f:
        json.dump(blog_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ JSONæ•¸æ“šç”Ÿæˆå®Œæˆ: {blog_data['total_posts']} ç¯‡æ–‡ç« ")
    return blog_data

def generate_sitemap():
    """ç”Ÿæˆç¶²ç«™åœ°åœ–"""
    sitemap_content = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">'''
    
    base_url = "https://www.horgoscpa.com"
    current_date = datetime.now().strftime('%Y-%m-%d')
    
    # ä¸»è¦é é¢
    main_pages = [
        ('/', '1.0', 'daily'),
        ('/blog.html', '0.9', 'daily'),
        ('/services.html', '0.8', 'weekly'),
        ('/contact.html', '0.7', 'monthly')
    ]
    
    for url, priority, changefreq in main_pages:
        sitemap_content += f'''
  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{current_date}</lastmod>
    <changefreq>{changefreq}</changefreq>
    <priority>{priority}</priority>
  </url>'''
    
    # æ·»åŠ åšå®¢æ–‡ç« 
    html_files = glob.glob("blog/*.html")
    for html_file in html_files:
        filename = os.path.basename(html_file)
        sitemap_content += f'''
  <url>
    <loc>{base_url}/blog/{filename}</loc>
    <lastmod>{current_date}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>'''
    
    sitemap_content += '''
</urlset>'''
    
    # ä¿å­˜sitemap.xml
    with open('sitemap.xml', 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    
    print("âœ“ ç¶²ç«™åœ°åœ–ç”Ÿæˆå®Œæˆ")

def main():
    """ä¸»å‡½æ•¸"""
    print("é–‹å§‹åŸ·è¡Œæ–‡æª”è™•ç†...")
    
    # æª¢æŸ¥è¼¸å…¥åƒæ•¸
    process_word = os.environ.get('INPUT_PROCESS_WORD', 'true').lower() == 'true'
    update_json = os.environ.get('INPUT_UPDATE_JSON', 'true').lower() == 'true'
    
    results = {
        'html_changed': False,
        'json_updated': False
    }
    
    # è™•ç†Wordæ–‡æª”
    if process_word:
        processed_count = process_word_documents()
        if processed_count > 0:
            results['html_changed'] = True
            print(f"âœ… Wordæ–‡æª”è™•ç†å®Œæˆ: {processed_count} å€‹æ–‡ä»¶")
        else:
            print("â„¹ï¸ æ²’æœ‰Wordæ–‡æª”éœ€è¦è™•ç†")
    
    # æ›´æ–°JSONæ•¸æ“š
    if update_json or results['html_changed']:
        blog_data = generate_blog_json()
        results['json_updated'] = True
        print("âœ… JSONæ•¸æ“šæ›´æ–°å®Œæˆ")
    
    # ç”Ÿæˆç¶²ç«™åœ°åœ–
    if results['json_updated']:
        generate_sitemap()
        print("âœ… ç¶²ç«™åœ°åœ–ç”Ÿæˆå®Œæˆ")
    
    # è¼¸å‡ºçµæœåˆ°GitHubç’°å¢ƒè®Šæ•¸
    github_output = os.environ.get('GITHUB_OUTPUT')
    if github_output:
        with open(github_output, 'a') as f:
            f.write(f"html_changed={'true' if results['html_changed'] else 'false'}\n")
            f.write(f"json_updated={'true' if results['json_updated'] else 'false'}\n")
    
    print("ğŸ‰ è™•ç†å®Œæˆ!")
    return results

if __name__ == "__main__":
    main()
SCRIPT_EOF
          
          echo "Pythonè…³æœ¬å‰µå»ºå®Œæˆ"

      - name: æª¢æŸ¥Wordæ–‡æª”
        id: check_word_docs
        run: |
          echo "æª¢æŸ¥Wordæ–‡æª”..."
          
          if [ -d "word-docs" ]; then
            DOCX_COUNT=$(find word-docs -maxdepth 1 -name "*.docx" ! -name "~*" 2>/dev/null | wc -l)
            echo "ç™¼ç¾ $DOCX_COUNT å€‹Wordæ–‡æª”"
            
            if [ "$DOCX_COUNT" -gt 0 ]; then
              echo "has_word_docs=true" >> $GITHUB_OUTPUT
              echo "Wordæ–‡æª”åˆ—è¡¨:"
              find word-docs -maxdepth 1 -name "*.docx" ! -name "~*" 2>/dev/null | head -5
            else
              echo "has_word_docs=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "has_word_docs=false" >> $GITHUB_OUTPUT
            echo "word-docsç›®éŒ„ä¸å­˜åœ¨"
          fi

      - name: åŸ·è¡Œæ–‡æª”è™•ç†
        id: process_docs
        if: github.event.inputs.process_word == 'true' || steps.check_word_docs.outputs.has_word_docs == 'true' || github.event.inputs.update_json == 'true'
        env:
          INPUT_PROCESS_WORD: ${{ github.event.inputs.process_word || 'true' }}
          INPUT_UPDATE_JSON: ${{ github.event.inputs.update_json || 'true' }}
        run: |
          echo "åŸ·è¡Œæ–‡æª”è™•ç†è…³æœ¬..."
          python process_documents.py

      - name: æª¢æŸ¥è™•ç†çµæœ
        id: check_results
        run: |
          echo "æª¢æŸ¥è™•ç†çµæœ..."
          
          # æª¢æŸ¥HTMLæ–‡ä»¶
          HTML_COUNT=$(find blog -name "*.html" 2>/dev/null | wc -l)
          echo "HTMLæ–‡ä»¶æ•¸é‡: $HTML_COUNT"
          
          # æª¢æŸ¥JSONæ–‡ä»¶
          if [ -f "assets/data/blog_posts.json" ]; then
            echo "blog_posts.json å­˜åœ¨"
            JSON_SIZE=$(stat -f%z "assets/data/blog_posts.json" 2>/dev/null || stat -c%s "assets/data/blog_posts.json" 2>/dev/null || echo "0")
            echo "JSONæ–‡ä»¶å¤§å°: $JSON_SIZE bytes"
          else
            echo "blog_posts.json ä¸å­˜åœ¨"
          fi
          
          # æª¢æŸ¥sitemap
          if [ -f "sitemap.xml" ]; then
            echo "sitemap.xml å­˜åœ¨"
          else
            echo "sitemap.xml ä¸å­˜åœ¨"
          fi
          
          # è¨­ç½®è¼¸å‡ºè®Šæ•¸
          if [ "$HTML_COUNT" -gt 0 ]; then
            echo "files_changed=true" >> $GITHUB_OUTPUT
          else
            echo "files_changed=false" >> $GITHUB_OUTPUT
          fi

      - name: æäº¤è®Šæ›´
        if: steps.check_results.outputs.files_changed == 'true'
        run: |
          echo "æäº¤è®Šæ›´åˆ°Git..."
          
          # æª¢æŸ¥Gitç‹€æ…‹
          git status
          
          # æ·»åŠ è®Šæ›´çš„æ–‡ä»¶
          git add blog/*.html 2>/dev/null || true
          git add assets/data/*.json 2>/dev/null || true
          git add sitemap.xml 2>/dev/null || true
          git add word-docs/processed/*.docx 2>/dev/null || true
          
          # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´
          if git diff --cached --quiet; then
            echo "æ²’æœ‰æ–‡ä»¶è®Šæ›´éœ€è¦æäº¤"
          else
            # çµ±è¨ˆè®Šæ›´
            ADDED_FILES=$(git diff --cached --name-only | wc -l)
            
            # å‰µå»ºæäº¤æ¶ˆæ¯
            COMMIT_MSG="è‡ªå‹•åŒ–è™•ç†: ç”Ÿæˆ/æ›´æ–° $ADDED_FILES å€‹æ–‡ä»¶"
            
            # æ·»åŠ è©³ç´°ä¿¡æ¯
            if git diff --cached --name-only | grep -q "blog/"; then
              HTML_CHANGES=$(git diff --cached --name-only | grep "blog/" | wc -l)
              COMMIT_MSG="$COMMIT_MSG (HTML: $HTML_CHANGES)"
            fi
            
            if git diff --cached --name-only | grep -q "assets/data/"; then
              COMMIT_MSG="$COMMIT_MSG (JSON: å·²æ›´æ–°)"
            fi
            
            COMMIT_MSG="$COMMIT_MSG [$(date '+%Y-%m-%d %H:%M:%S')]"
            
            # æäº¤è®Šæ›´
            git commit -m "$COMMIT_MSG"
            
            # æ¨é€è®Šæ›´
            git push
            
            echo "âœ… è®Šæ›´å·²æäº¤ä¸¦æ¨é€"
            echo "æäº¤æ¶ˆæ¯: $COMMIT_MSG"
          fi

      - name: åŸ·è¡Œçµæœå ±å‘Š
        run: |
          echo "================================================"
          echo "            è‡ªå‹•åŒ–è™•ç†åŸ·è¡Œå®Œæˆ"
          echo "================================================"
          echo ""
          echo "ğŸ• åŸ·è¡Œæ™‚é–“: $(date '+%Y-%m-%d %H:%M:%S UTC')"
          echo "ğŸŒ å°ç£æ™‚é–“: $(TZ='Asia/Taipei' date '+%Y-%m-%d %H:%M:%S %Z')"
          echo ""
          
          # æ–‡ä»¶çµ±è¨ˆ
          echo "ğŸ“Š æ–‡ä»¶çµ±è¨ˆ:"
          HTML_COUNT=$(find blog -name "*.html" 2>/dev/null | wc -l)
          JSON_COUNT=$(find assets/data -name "*.json" 2>/dev/null | wc -l)
          DOCX_COUNT=$(find word-docs -name "*.docx" 2>/dev/null | wc -l)
          PROCESSED_COUNT=$(find word-docs/processed -name "*.docx" 2>/dev/null | wc -l)
          
          echo "  ğŸ“„ HTMLæ–‡ä»¶: $HTML_COUNT å€‹"
          echo "  ğŸ“Š JSONæ–‡ä»¶: $JSON_COUNT å€‹"
          echo "  ğŸ“ Wordæ–‡æª”: $DOCX_COUNT å€‹"
          echo "  âœ… å·²è™•ç†: $PROCESSED_COUNT å€‹"
          
          # é¡¯ç¤ºæœ€æ–°æ–‡ä»¶
          echo ""
          echo "ğŸ“‹ æœ€æ–°ç”Ÿæˆçš„HTMLæ–‡ä»¶:"
          if [ "$HTML_COUNT" -gt 0 ]; then
            find blog -name "*.html" -printf "%f\n" 2>/dev/null | sort -r | head -5 | sed 's/^/  ğŸ“ /'
          else
            echo "  ï¼ˆç„¡HTMLæ–‡ä»¶ï¼‰"
          fi
          
          # æª¢æŸ¥é…ç½®æ–‡ä»¶
          echo ""
          echo "ğŸ”§ é…ç½®æ–‡ä»¶ç‹€æ…‹:"
          for file in "assets/data/translation_dict.json" "assets/data/processed_files.json" "assets/data/blog_posts.json"; do
            if [ -f "$file" ]; then
              echo "  âœ… $file"
            else
              echo "  âŒ $file (ç¼ºå¤±)"
            fi
          done
          
          # ç¶²ç«™åœ°åœ–ç‹€æ…‹
          echo ""
          echo "ğŸ—ºï¸ ç¶²ç«™åœ°åœ–:"
          if [ -f "sitemap.xml" ]; then
            SITEMAP_URLS=$(grep -c "<url>" sitemap.xml 2>/dev/null || echo "0")
            echo "  âœ… sitemap.xml ($SITEMAP_URLS å€‹URL)"
          else
            echo "  âŒ sitemap.xml (æœªç”Ÿæˆ)"
          fi
          
          echo ""
          echo "ğŸ‰ è‡ªå‹•åŒ–è™•ç†æµç¨‹åŸ·è¡Œå®Œæˆï¼"
          echo "ğŸŒ ç¶²ç«™åœ°å€: https://www.horgoscpa.com"
          echo "ğŸ“ åšå®¢é é¢: https://www.horgoscpa.com/blog.html"