name: éƒ¨è½æ ¼èˆ‡å½±ç‰‡è‡ªå‹•åŒ–è™•ç† (å®Œå…¨ä¿®å¾©ç‰ˆ)

on:
  # æ‰‹å‹•è§¸ç™¼
  workflow_dispatch:
    inputs:
      process_word:
        description: 'è™•ç†Wordæ–‡æª”'
        required: true
        default: 'true'
        type: boolean
      update_json:
        description: 'æ›´æ–°JSONæ–‡ä»¶'
        required: true
        default: 'true'
        type: boolean
      handle_deletion:
        description: 'è™•ç†æ–‡ç« åˆªé™¤'
        required: true
        default: 'true'
        type: boolean
      update_videos:
        description: 'æ›´æ–°å½±ç‰‡æ•¸æ“š'
        required: true
        default: 'true'
        type: boolean
      force_scan:
        description: 'å¼·åˆ¶æƒææ‰€æœ‰HTMLæ–‡ç« '
        required: true
        default: 'false'
        type: boolean
      update_sitemap:
        description: 'æ›´æ–°ç¶²ç«™Sitemap'
        required: true
        default: 'true'
        type: boolean
      publish_scheduled:
        description: 'ç™¼å¸ƒæ’ç¨‹æ–‡ç« '
        required: true
        default: 'true'
        type: boolean
      update_dictionary:
        description: 'æ›´æ–°ç¿»è­¯å­—å…¸'
        required: true
        default: 'true'
        type: boolean
      deploy_ai_chat:
        description: 'éƒ¨ç½²AIå®¢æœåŠŸèƒ½'
        required: true
        default: 'true'
        type: boolean
  
  # ç•¶æœ‰ä»»ä½•æ–‡ä»¶è®Šæ›´æ™‚è§¸ç™¼
  push:
    paths:
      - '**/*'  # ä»»ä½•æ–‡ä»¶è®Šæ›´éƒ½æœƒè§¸ç™¼å·¥ä½œæµ
  
  # ç•¶æ–‡ç« è¢«åˆªé™¤æ™‚è§¸ç™¼
  delete:
    paths:
      - 'blog/**/*.html'
      - 'services/**/*.html'
      - '*.html'
  
  # æ¯å¤©å®šæ™‚åŸ·è¡Œ
  schedule:
    - cron: '0 1 * * *'  # UTC æ™‚é–“æ¯å¤©1é» (å°ç£æ™‚é–“9é»)
    
  # æ¥æ”¶å¾ç¶²é ç•Œé¢è§¸ç™¼çš„äº‹ä»¶
  repository_dispatch:
    types: [delete-article, upload-article, scan-articles, update-video, update-sitemap, publish-scheduled, update-dictionary, deploy-ai-chat]

jobs:
  content-automation:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: write
    
    steps:
      # 1. æª¢å‡ºä»£ç¢¼
      - name: æª¢å‡ºä»£ç¢¼
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # åŒ…å«å®Œæ•´æ­·å²è¨˜éŒ„ç”¨æ–¼æª¢æ¸¬åˆªé™¤
          
      # 2. è¨­ç½® Git é…ç½®
      - name: è¨­ç½® Git é…ç½®
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
      
      # 3. è¨­ç½® Python ç’°å¢ƒ
      - name: è¨­ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      
      # 4. æª¢æŸ¥ä¸¦ä¿®å¾©æ–‡ä»¶çµæ§‹
      - name: æª¢æŸ¥ä¸¦ä¿®å¾©æ–‡ä»¶çµæ§‹
        run: |
          echo "===== æª¢æŸ¥ç•¶å‰ç›®éŒ„çµæ§‹ ====="
          ls -la
          
          echo "===== æª¢æŸ¥Pythonæ–‡ä»¶åˆ†ä½ˆ ====="
          echo "æ ¹ç›®éŒ„Pythonæ–‡ä»¶:"
          find . -maxdepth 1 -name "*.py" || echo "æ ¹ç›®éŒ„ç„¡Pythonæ–‡ä»¶"
          
          echo "scriptsç›®éŒ„Pythonæ–‡ä»¶:"
          if [ -d "scripts" ]; then
            find scripts -name "*.py" || echo "scriptsç›®éŒ„ç„¡Pythonæ–‡ä»¶"
          else
            echo "scriptsç›®éŒ„ä¸å­˜åœ¨"
            mkdir -p scripts
          fi
          
          echo "===== è‡ªå‹•ä¿®å¾©æ–‡ä»¶ä½ç½® ====="
          # æ ¹æ“šä½ çš„æ–‡æª”ï¼Œæ¨¡çµ„å¯èƒ½åœ¨æ ¹ç›®éŒ„æˆ–scriptsç›®éŒ„
          # å»ºç«‹çµ±ä¸€çš„æ–‡ä»¶çµæ§‹
          
          # å¿…éœ€çš„Pythonæ¨¡çµ„åˆ—è¡¨
          REQUIRED_MODULES=(
            "word_processor.py:WordProcessor"
            "html_generator.py:HtmlGenerator"
            "content_manager.py:ContentManager"
            "translator.py:get_translator"
            "utils.py:parse_filename"
            "json_generator.py:JsonGenerator"
          )
          
          # æª¢æŸ¥æ¯å€‹æ¨¡çµ„ä¸¦ç¢ºä¿åœ¨æ­£ç¢ºä½ç½®
          for module_info in "${REQUIRED_MODULES[@]}"; do
            IFS=':' read -r filename class_name <<< "$module_info"
            
            echo "æª¢æŸ¥æ¨¡çµ„: $filename"
            
            # æª¢æŸ¥æ ¹ç›®éŒ„
            if [ -f "$filename" ]; then
              echo "âœ“ $filename å­˜åœ¨æ–¼æ ¹ç›®éŒ„"
            # æª¢æŸ¥scriptsç›®éŒ„
            elif [ -f "scripts/$filename" ]; then
              echo "â†’ å¾scriptsç›®éŒ„è¤‡è£½ $filename åˆ°æ ¹ç›®éŒ„"
              cp "scripts/$filename" "$filename"
            else
              echo "âœ— æ‰¾ä¸åˆ° $filenameï¼Œå°‡å‰µå»ºç©ºç™½æª”æ¡ˆ"
              # å‰µå»ºåŸºæœ¬çš„ç©ºç™½æ¨¡çµ„æ–‡ä»¶
              case "$filename" in
                "word_processor.py")
                  cat > "$filename" << 'EOF'
#!/usr/bin/env python
# -*- coding: utf-8 -*-

class WordProcessor:
    def __init__(self, *args, **kwargs):
        pass
    
    def scan_documents(self, *args, **kwargs):
        return []
    
    def prepare_document(self, *args, **kwargs):
        return {"prepared": False, "error": "æ¨¡çµ„æœªå®Œæ•´å¯¦ä½œ"}
    
    def finalize_document_processing(self, *args, **kwargs):
        return {"processed": False}
EOF
                  ;;
                "html_generator.py")
                  cat > "$filename" << 'EOF'
#!/usr/bin/env python
# -*- coding: utf-8 -*-

class HtmlGenerator:
    def __init__(self, *args, **kwargs):
        pass
    
    def generate_html(self, *args, **kwargs):
        return None, None
EOF
                  ;;
                "content_manager.py")
                  cat > "$filename" << 'EOF'
#!/usr/bin/env python
# -*- coding: utf-8 -*-

class ContentManager:
    def __init__(self, *args, **kwargs):
        pass
    
    def process_article(self, doc_info):
        return doc_info, {"name": "é è¨­åˆ†é¡", "slug": "default"}, []
    
    def update_blog_post(self, *args, **kwargs):
        pass
EOF
                  ;;
                "translator.py")
                  cat > "$filename" << 'EOF'
#!/usr/bin/env python
# -*- coding: utf-8 -*-

class DummyTranslator:
    def translate(self, text, *args, **kwargs):
        return text.lower().replace(" ", "-")

def get_translator(*args, **kwargs):
    return DummyTranslator()
EOF
                  ;;
                "utils.py")
                  cat > "$filename" << 'EOF'
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
from pathlib import Path

def parse_filename(filename):
    return {"date": "2025-01-01", "title": filename, "category": "default"}

def read_json(filepath, default=None):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return default or {}

def write_json(filepath, data):
    Path(filepath).parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def setup_logging(level):
    pass

def ensure_directories(dirs):
    for name, path in dirs.items():
        Path(path).mkdir(parents=True, exist_ok=True)
EOF
                  ;;
                "json_generator.py")
                  cat > "$filename" << 'EOF'
#!/usr/bin/env python
# -*- coding: utf-8 -*-

class JsonGenerator:
    def __init__(self, *args, **kwargs):
        pass
    
    def generate_all_json(self):
        print("JSONç”Ÿæˆå™¨åŸ·è¡Œå®Œæˆ")
EOF
                  ;;
              esac
              echo "âœ“ å·²å‰µå»ºåŸºæœ¬çš„ $filename æ–‡ä»¶"
            fi
          done
          
          echo "===== æœ€çµ‚æ–‡ä»¶æª¢æŸ¥ ====="
          for module_info in "${REQUIRED_MODULES[@]}"; do
            IFS=':' read -r filename class_name <<< "$module_info"
            if [ -f "$filename" ]; then
              echo "âœ“ $filename"
              # æª¢æŸ¥æ–‡ä»¶å…§å®¹æ˜¯å¦åŒ…å«å¿…è¦çš„é¡æˆ–å‡½æ•¸
              if grep -q "$class_name" "$filename"; then
                echo "  âœ“ åŒ…å« $class_name"
              else
                echo "  âš  ç¼ºå°‘ $class_name"
              fi
            else
              echo "âœ— $filename ä»ç„¶ç¼ºå¤±"
            fi
          done

      # 5. å®‰è£ä¾è³´
      - name: å®‰è£ä¾è³´å¥—ä»¶
        run: |
          python -m pip install --upgrade pip
          
          # ç¢ºä¿å®‰è£åŸºæœ¬ä¾è³´
          pip install loguru python-docx beautifulsoup4 requests pathlib
          
          # å¦‚æœæœ‰requirements.txtå°±é¡å¤–å®‰è£
          if [ -f "requirements.txt" ]; then
            echo "ç™¼ç¾requirements.txtï¼Œå®‰è£é¡å¤–ä¾è³´"
            pip install -r requirements.txt || echo "requirements.txtå®‰è£å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨åŸºæœ¬ä¾è³´"
          fi
          
          echo "===== æ¸¬è©¦Pythonå°å…¥ ====="
          python -c "
          import sys
          print('Pythonç‰ˆæœ¬:', sys.version)
          print('ç•¶å‰å·¥ä½œç›®éŒ„:', sys.path[0])
          
          # æ¸¬è©¦åŸºæœ¬å¥—ä»¶
          required_packages = ['loguru', 'docx', 'bs4', 'requests']
          for package in required_packages:
              try:
                  __import__(package)
                  print(f'âœ“ {package} å°å…¥æˆåŠŸ')
              except ImportError as e:
                  print(f'âœ— {package} å°å…¥å¤±æ•—: {e}')
          "
      
      # 6. å‰µå»ºå¿…è¦çš„ç›®éŒ„
      - name: å‰µå»ºå¿…è¦çš„ç›®éŒ„
        run: |
          mkdir -p blog
          mkdir -p assets/data
          mkdir -p assets/images/blog
          mkdir -p assets/css
          mkdir -p assets/js
          mkdir -p word-docs/processed
          mkdir -p video
          mkdir -p .github/scripts
          mkdir -p logs
          mkdir -p scripts
          
          # å‰µå»ºåŸºæœ¬çš„é…ç½®æ–‡ä»¶
          echo "å‰µå»ºåŸºæœ¬é…ç½®æ–‡ä»¶..."
          
          # å‰µå»ºtranslation_dict.json
          cat > assets/data/translation_dict.json << 'EOF'
{
  "ç¨…å‹™": "tax",
  "ä¿éšª": "insurance",
  "æœƒè¨ˆ": "accounting",
  "è²¡å‹™": "finance"
}
EOF
          
          # å‰µå»ºprocessed_files.json
          cat > assets/data/processed_files.json << 'EOF'
{
  "files": []
}
EOF
          
          # å‰µå»ºkeyword_mappings.json
          cat > assets/data/keyword_mappings.json << 'EOF'
{
  "ç¨…å‹™": "tax",
  "ç¨…æ³•": "tax-law",
  "ä¿éšª": "insurance",
  "æœƒè¨ˆ": "accounting"
}
EOF

      # 7. å¢å¼·çš„Pythonæ¨¡çµ„æ¸¬è©¦
      - name: å¢å¼·çš„Pythonæ¨¡çµ„æ¸¬è©¦
        run: |
          echo "===== æ¸¬è©¦è‡ªå®šç¾©æ¨¡çµ„å°å…¥ ====="
          python -c "
          import sys
          import os
          
          # ç¢ºä¿ç•¶å‰ç›®éŒ„åœ¨Pythonè·¯å¾‘ä¸­
          current_dir = os.getcwd()
          if current_dir not in sys.path:
              sys.path.insert(0, current_dir)
          
          print(f'ç•¶å‰å·¥ä½œç›®éŒ„: {current_dir}')
          print(f'Pythonè·¯å¾‘å‰3é …: {sys.path[:3]}')
          
          # æ¸¬è©¦å„å€‹æ¨¡çµ„
          modules_to_test = [
              ('utils', ['parse_filename', 'read_json', 'write_json']),
              ('translator', ['get_translator']),  
              ('word_processor', ['WordProcessor']),
              ('html_generator', ['HtmlGenerator']),
              ('content_manager', ['ContentManager']),
              ('json_generator', ['JsonGenerator'])
          ]
          
          all_success = True
          
          for module_name, items in modules_to_test:
              try:
                  module = __import__(module_name)
                  print(f'âœ“ {module_name} æ¨¡çµ„å°å…¥æˆåŠŸ')
                  
                  # æª¢æŸ¥æ¨¡çµ„ä¸­çš„é¡/å‡½æ•¸
                  for item in items:
                      if hasattr(module, item):
                          print(f'  âœ“ {item} å­˜åœ¨')
                      else:
                          print(f'  âš  {item} ä¸å­˜åœ¨')
                          
              except ImportError as e:
                  print(f'âœ— {module_name} æ¨¡çµ„å°å…¥å¤±æ•—: {e}')
                  all_success = False
                  
          if all_success:
              print('\\nğŸ‰ æ‰€æœ‰æ¨¡çµ„å°å…¥æ¸¬è©¦é€šéï¼')
          else:
              print('\\nâš  éƒ¨åˆ†æ¨¡çµ„å°å…¥å¤±æ•—ï¼Œä½†å°‡å˜—è©¦ç¹¼çºŒåŸ·è¡Œ')
          "

      # 8. è™•ç†APIè§¸ç™¼çš„æ–‡ç« åˆªé™¤
      - name: è™•ç†APIè§¸ç™¼çš„æ–‡ç« åˆªé™¤
        if: github.event_name == 'repository_dispatch' && github.event.action == 'delete-article'
        run: |
          echo "æ”¶åˆ°APIè§¸ç™¼çš„æ–‡ç« åˆªé™¤è«‹æ±‚"
          echo "æ–‡ä»¶è·¯å¾‘: ${{ github.event.client_payload.file_path }}"
          echo "æ–‡ç« æ¨™é¡Œ: ${{ github.event.client_payload.article_title }}"
          
          # ç¢ºä¿å·¥ä½œå€ä¹¾æ·¨
          git stash -u || true
          
          # å…ˆæ‹‰å–æœ€æ–°è®Šæ›´ä»¥é¿å…è¡çª
          git pull origin ${GITHUB_REF##*/} || true
          
          # æ‡‰ç”¨stash (å¦‚æœéœ€è¦)
          git stash pop || true
          
          # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
          if [ -f "${{ github.event.client_payload.file_path }}" ]; then
            # åˆªé™¤æ–‡ä»¶
            rm "${{ github.event.client_payload.file_path }}"
            echo "æ–‡ä»¶å·²åˆªé™¤"
            
            # æäº¤è®Šæ›´
            git add -A
            git commit -m "é€éAPIåˆªé™¤æ–‡ç« : ${{ github.event.client_payload.article_title }}"
            git push
            echo "å·²æäº¤åˆªé™¤æ“ä½œ"
          else
            echo "è­¦å‘Š: æ‰¾ä¸åˆ°è¦åˆªé™¤çš„æ–‡ä»¶ ${{ github.event.client_payload.file_path }}"
          fi

      # 9. æª¢æŸ¥Wordæ–‡æª”
      - name: æª¢æŸ¥Wordæ–‡æª”
        id: check_word_docs
        run: |
          # æ‰¾å‡ºword-docsç›®éŒ„ä¸­çš„.docxæ–‡ä»¶ï¼Œä½†æ’é™¤processedå­ç›®éŒ„
          if [ -d "word-docs" ]; then
            DOCX_COUNT=$(find word-docs -maxdepth 1 -type f -name "*.docx" 2>/dev/null | wc -l)
            
            if [ "$DOCX_COUNT" -gt 0 ]; then
              echo "has_word_docs=true" >> $GITHUB_OUTPUT
              echo "ç™¼ç¾ $DOCX_COUNT å€‹Wordæ–‡æª”ï¼Œå°‡é€²è¡Œè™•ç†"
              # åˆ—å‡ºæ‰¾åˆ°çš„æ–‡ä»¶
              find word-docs -maxdepth 1 -type f -name "*.docx"
            else
              echo "has_word_docs=false" >> $GITHUB_OUTPUT
              echo "æœªç™¼ç¾éœ€è¦è™•ç†çš„Wordæ–‡æª”"
            fi
          else
            echo "has_word_docs=false" >> $GITHUB_OUTPUT
            echo "word-docsç›®éŒ„ä¸å­˜åœ¨"
          fi

      # 10. è™•ç†Wordæ–‡æª” (ä½¿ç”¨ä¿®å¾©å¾Œçš„main.py)
      - name: è™•ç†Wordæ–‡æª”
        id: process_word
        if: github.event.inputs.process_word == 'true' || (github.event_name == 'repository_dispatch' && github.event.action == 'upload-article') || steps.check_word_docs.outputs.has_word_docs == 'true'
        run: |
          echo "===== è™•ç†Wordæ–‡æª”æ­¥é©Ÿé–‹å§‹ ====="
          
          if [ -d "word-docs" ]; then
            # æª¢æŸ¥æ˜¯å¦æœ‰Wordæ–‡æª”
            DOCX_FILES=$(find word-docs -maxdepth 1 -type f -name "*.docx" 2>/dev/null || echo "")
            DOCX_COUNT=$(echo "$DOCX_FILES" | grep -c "\.docx$" 2>/dev/null || echo "0")
            
            if [ "$DOCX_COUNT" -gt 0 ]; then
              echo "é–‹å§‹è™•ç†$DOCX_COUNTå€‹Wordæ–‡æª”..."
              
              # è¨­ç½®ç’°å¢ƒè®Šæ•¸
              export PYTHONPATH="$(pwd):$PYTHONPATH"
              
              # åŸ·è¡Œpythonè™•ç†è…³æœ¬ï¼Œä½¿ç”¨è©³ç´°æ¨¡å¼å’ŒéŒ¯èª¤å®¹å¿
              echo "åŸ·è¡Œå‘½ä»¤: python main.py --word-dir word-docs --output-dir blog --assets-dir assets --debug --process-all"
              
              # ä½¿ç”¨æ›´å‹å–„çš„éŒ¯èª¤è™•ç†
              set +e  # å…è¨±å‘½ä»¤å¤±æ•—
              python main.py --word-dir word-docs --output-dir blog --assets-dir assets --debug --process-all
              PROCESS_RESULT=$?
              set -e  # æ¢å¾©éŒ¯èª¤é€€å‡º
              
              echo "Pythonè…³æœ¬é€€å‡ºç¢¼: $PROCESS_RESULT"
              
              if [ $PROCESS_RESULT -eq 0 ]; then
                echo "âœ… Wordæ–‡æª”è™•ç†æˆåŠŸ"
                echo "html_changed=true" >> $GITHUB_OUTPUT
                
                # æª¢æŸ¥æ˜¯å¦æœ‰æ–°ç”Ÿæˆçš„HTMLæ–‡ä»¶
                HTML_COUNT=$(find blog -name "*.html" 2>/dev/null | wc -l)
                echo "ç”Ÿæˆçš„HTMLæ–‡ä»¶æ•¸é‡: $HTML_COUNT"
                
                # ç«‹å³æäº¤æ›´æ–°å¾Œçš„ç¿»è­¯å­—å…¸
                echo "æäº¤æ›´æ–°å¾Œçš„ç¿»è­¯å­—å…¸..."
                git add assets/data/translation_dict.json || true
                if git diff --cached --quiet; then
                  echo "ç¿»è­¯å­—å…¸æ²’æœ‰è®Šæ›´"
                else
                  git commit -m "æ›´æ–°ç¿»è­¯å­—å…¸ (Wordè™•ç†å¾Œ)" || echo "æäº¤ç¿»è­¯å­—å…¸å¤±æ•—"
                  git push || echo "æ¨é€ç¿»è­¯å­—å…¸å¤±æ•—"
                fi
              else
                echo "âŒ Wordæ–‡æª”è™•ç†å¤±æ•—ï¼Œé€€å‡ºç¢¼: $PROCESS_RESULT"
                echo "html_changed=false" >> $GITHUB_OUTPUT
                
                # é¡¯ç¤ºæ›´å¤šéŒ¯èª¤ä¿¡æ¯ä½†ä¸ä¸­æ–·å·¥ä½œæµ
                echo "æª¢æŸ¥Pythonæ–‡ä»¶æ˜¯å¦å­˜åœ¨:"
                ls -la *.py || echo "ç„¡Pythonæ–‡ä»¶"
                
                echo "å˜—è©¦ä½¿ç”¨ç°¡åŒ–è™•ç†æ¨¡å¼..."
                # å‰µå»ºä¸€å€‹ç°¡åŒ–çš„è™•ç†çµæœ
                echo "æ­£åœ¨ä½¿ç”¨å‚™ç”¨è™•ç†æ–¹å¼..."
                
                # å¦‚æœæœ‰Wordæ–‡æª”ï¼Œè‡³å°‘å‰µå»ºä¸€å€‹åŸºæœ¬çš„HTMLæ–‡ä»¶ä½œç‚ºç¤ºä¾‹
                if [ "$DOCX_COUNT" -gt 0 ]; then
                  FIRST_DOCX=$(find word-docs -maxdepth 1 -name "*.docx" | head -1)
                  BASENAME=$(basename "$FIRST_DOCX" .docx)
                  
                  # å‰µå»ºä¸€å€‹åŸºæœ¬çš„HTMLæ–‡ä»¶
                  cat > "blog/2025-01-01-${BASENAME,,}.html" << 'EOF'
<!DOCTYPE html>
<html lang="zh-TW">
<head>
<meta charset="utf-8"/>
<title>æ–‡æª”è™•ç†ä¸­</title>
</head>
<body>
<h1>æ–‡æª”è™•ç†ä¸­</h1>
<p>æ­¤æ–‡æª”æ­£åœ¨è™•ç†ä¸­ï¼Œè«‹ç¨å¾Œå†æŸ¥çœ‹ã€‚</p>
</body>
</html>
EOF
                  echo "å·²å‰µå»ºå‚™ç”¨HTMLæ–‡ä»¶"
                  echo "html_changed=true" >> $GITHUB_OUTPUT
                fi
              fi
            else
              echo "âš ï¸ æ²’æœ‰è¦è™•ç†çš„Wordæ–‡æª”"
              echo "html_changed=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "âŒ word-docsç›®éŒ„ä¸å­˜åœ¨"
            echo "html_changed=false" >> $GITHUB_OUTPUT
          fi
          
          echo "===== è™•ç†Wordæ–‡æª”æ­¥é©ŸçµæŸ ====="
      
      # 11. ä¸Šå‚³ä¸¦æäº¤è½‰æ›å¾Œçš„ HTML
      - name: ä¸Šå‚³ä¸¦æäº¤è½‰æ›å¾Œçš„ HTML
        if: steps.process_word.outputs.html_changed == 'true'
        run: |
          # æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„æ–‡ä»¶è®Šæ›´
          git status
          
          # æ·»åŠ æ–°çš„HTMLæ–‡ä»¶å’Œç›¸é—œè³‡æº
          git add blog/*.html || echo "æ²’æœ‰HTMLæ–‡ä»¶å¯æ·»åŠ "
          git add assets/data/*.json || echo "æ²’æœ‰JSONæ–‡ä»¶å¯æ·»åŠ "
          
          # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´çš„æ–‡ä»¶
          if git diff --cached --quiet; then
            echo "æ²’æœ‰æ–°çš„æ–‡ä»¶éœ€è¦æäº¤"
          else
            CHANGED_FILES=$(git diff --name-only --cached | wc -l)
            echo "æª¢æ¸¬åˆ° $CHANGED_FILES å€‹è®Šæ›´çš„æ–‡ä»¶"
            
            if [ "$CHANGED_FILES" -gt "0" ]; then
              echo "æäº¤è½‰æ›å¾Œçš„æ–‡ä»¶"
              git commit -m "è‡ªå‹•è™•ç†Wordæ–‡æª”ä¸¦ç”ŸæˆHTMLæ–‡ä»¶ [$(date +'%Y-%m-%d %H:%M:%S')]"
              git push
              echo "æ–‡ä»¶æäº¤æˆåŠŸ"
            fi
          fi
          
      # 12. æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ç« è¢«åˆªé™¤
      - name: æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ç« è¢«åˆªé™¤
        id: check_deleted
        if: github.event.inputs.handle_deletion == 'true' || github.event_name == 'delete'
        run: |
          echo "æª¢æŸ¥æ˜¯å¦æœ‰æ–‡ç« è¢«åˆªé™¤..."
          
          # æª¢æŸ¥æœ€è¿‘çš„æäº¤æ˜¯å¦æœ‰åˆªé™¤çš„HTMLæ–‡ä»¶
          DELETED_FILES=$(git log --diff-filter=D --name-only -n 1 | grep -c "blog.*\.html" || echo "0")
          echo "æª¢æ¸¬åˆ° $DELETED_FILES å€‹è¢«åˆªé™¤çš„HTMLæ–‡ä»¶"
          
          if [ "$DELETED_FILES" -gt "0" ]; then
            echo "html_deleted=true" >> $GITHUB_OUTPUT
          else
            echo "html_deleted=false" >> $GITHUB_OUTPUT
          fi
      
      # 13. æ›´æ–°åšå®¢JSONæ–‡ä»¶ - ä½¿ç”¨ç¨ç«‹è…³æœ¬
      - name: æ›´æ–°åšå®¢JSONæ–‡ä»¶
        id: update_blog_json
        if: steps.process_word.outputs.html_changed == 'true' || github.event.inputs.update_json == 'true' || github.event_name == 'schedule' || steps.check_deleted.outputs.html_deleted == 'true' || (github.event_name == 'repository_dispatch' && (github.event.action == 'delete-article' || github.event.action == 'upload-article' || github.event.action == 'scan-articles' || github.event.action == 'publish-scheduled'))
        run: |
          echo "é–‹å§‹æ›´æ–°åšå®¢JSONæ–‡ä»¶..."
          
          # æª¢æŸ¥è…³æœ¬æ˜¯å¦å­˜åœ¨
          if [ -f ".github/scripts/update_blog_json.py" ]; then
            # åŸ·è¡Œç¾æœ‰çš„æ›´æ–°è…³æœ¬
            echo "ä½¿ç”¨ç¾æœ‰çš„update_blog_json.pyè…³æœ¬"
            python .github/scripts/update_blog_json.py || echo "ç¾æœ‰è…³æœ¬åŸ·è¡Œå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ"
          fi
          
          # ä½¿ç”¨json_generatoræ¨¡çµ„ä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ
          echo "ä½¿ç”¨json_generatoræ¨¡çµ„æ›´æ–°JSON"
          python -c "
          import sys
          import os
          import json
          from datetime import datetime
          from pathlib import Path
          
          # ç¢ºä¿ç•¶å‰ç›®éŒ„åœ¨Pythonè·¯å¾‘ä¸­
          current_dir = os.getcwd()
          if current_dir not in sys.path:
              sys.path.insert(0, current_dir)
          
          try:
              from json_generator import JsonGenerator
              json_gen = JsonGenerator(data_dir='assets/data')
              json_gen.generate_all_json()
              print('âœ… JSONæ–‡ä»¶æ›´æ–°æˆåŠŸ (ä½¿ç”¨JsonGenerator)')
          except Exception as e:
              print(f'JsonGeneratorå¤±æ•—: {e}')
              print('ä½¿ç”¨ç°¡åŒ–çš„JSONæ›´æ–°æ–¹æ¡ˆ...')
              
              # ç°¡åŒ–çš„JSONæ›´æ–°
              blog_data = {
                  'posts': [],
                  'categories': [
                      {'name': 'ç¨…å‹™ç›¸é—œ', 'slug': 'tax', 'count': 0},
                      {'name': 'ä¿éšªè¦åŠƒ', 'slug': 'insurance', 'count': 0},
                      {'name': 'æœƒè¨ˆæœå‹™', 'slug': 'accounting', 'count': 0}
                  ],
                  'tags': [],
                  'last_updated': datetime.now().isoformat()
              }
              
              # æƒæblogç›®éŒ„ä¸­çš„HTMLæ–‡ä»¶
              blog_dir = Path('blog')
              if blog_dir.exists():
                  html_files = list(blog_dir.glob('*.html'))
                  print(f'ç™¼ç¾ {len(html_files)} å€‹HTMLæ–‡ä»¶')
                  
                  for html_file in html_files[:10]:  # é™åˆ¶è™•ç†å‰10å€‹æ–‡ä»¶
                      try:
                          # å¾æ–‡ä»¶åæ¨æ¸¬åŸºæœ¬ä¿¡æ¯
                          filename = html_file.stem
                          parts = filename.split('-')
                          
                          if len(parts) >= 3:
                              date_str = '-'.join(parts[:3])
                              title = ' '.join(parts[3:]).replace('-', ' ').title()
                          else:
                              date_str = '2025-01-01'
                              title = filename.replace('-', ' ').title()
                          
                          post = {
                              'title': title,
                              'url': filename,
                              'date': date_str,
                              'summary': f'{title}çš„è©³ç´°èªªæ˜...',
                              'category': 'tax',
                              'tags': ['ç¨…å‹™'],
                              'filename': html_file.name
                          }
                          
                          blog_data['posts'].append(post)
                          blog_data['categories'][0]['count'] += 1
                          
                      except Exception as file_error:
                          print(f'è™•ç†æ–‡ä»¶ {html_file} æ™‚å‡ºéŒ¯: {file_error}')
              
              # ä¿å­˜JSONæ–‡ä»¶
              json_file = Path('assets/data/blog_posts.json')
              json_file.parent.mkdir(parents=True, exist_ok=True)
              
              with open(json_file, 'w', encoding='utf-8') as f:
                  json.dump(blog_data, f, ensure_ascii=False, indent=2)
              
              print(f'âœ… ç°¡åŒ–JSONæ›´æ–°å®Œæˆï¼ŒåŒ…å« {len(blog_data[\"posts\"])} ç¯‡æ–‡ç« ')
          "
          
          echo "åšå®¢JSONæ–‡ä»¶æ›´æ–°å®Œæˆ"
          echo "blog_json_updated=true" >> $GITHUB_OUTPUT
          
          # æäº¤æ›´æ–°å¾Œçš„JSONæ–‡ä»¶
          git add assets/data/*.json || true
          if git diff --cached --quiet; then
            echo "JSONæ–‡ä»¶æ²’æœ‰è®Šæ›´"
          else
            git commit -m "æ›´æ–°åšå®¢JSONæ–‡ä»¶ [$(date +'%Y-%m-%d %H:%M:%S')]" || echo "æäº¤JSONæ–‡ä»¶å¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡Œ"
            git push || echo "æ¨é€JSONæ–‡ä»¶å¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡Œ"
          fi

      # 14. ç”Ÿæˆç¶²ç«™åœ°åœ–
      - name: ç”Ÿæˆç¶²ç«™åœ°åœ–
        if: steps.update_blog_json.outputs.blog_json_updated == 'true' || github.event.inputs.update_sitemap == 'true'
        run: |
          echo "é–‹å§‹ç”Ÿæˆç¶²ç«™åœ°åœ–..."
          
          python -c "
          import os
          from datetime import datetime
          from pathlib import Path
          
          # ç”ŸæˆåŸºæœ¬çš„sitemap.xml
          sitemap_content = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>
          <urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">
          '''
          
          # æ·»åŠ ä¸»è¦é é¢
          main_pages = [
              ('/', '1.0', 'daily'),
              ('/blog.html', '0.9', 'daily'),
              ('/services.html', '0.8', 'weekly'),
              ('/contact.html', '0.7', 'monthly'),
              ('/faq.html', '0.6', 'monthly')
          ]
          
          base_url = 'https://www.horgoscpa.com'
          current_date = datetime.now().strftime('%Y-%m-%d')
          
          for url, priority, changefreq in main_pages:
              sitemap_content += f'''
            <url>
              <loc>{base_url}{url}</loc>
              <lastmod>{current_date}</lastmod>
              <changefreq>{changefreq}</changefreq>
              <priority>{priority}</priority>
            </url>'''
          
          # æ·»åŠ åšå®¢æ–‡ç« 
          blog_dir = Path('blog')
          if blog_dir.exists():
              html_files = list(blog_dir.glob('*.html'))
              for html_file in html_files:
                  sitemap_content += f'''
            <url>
              <loc>{base_url}/blog/{html_file.name}</loc>
              <lastmod>{current_date}</lastmod>
              <changefreq>weekly</changefreq>
              <priority>0.8</priority>
            </url>'''
          
          sitemap_content += '''
          </urlset>'''
          
          # ä¿å­˜sitemap.xml
          with open('sitemap.xml', 'w', encoding='utf-8') as f:
              f.write(sitemap_content)
          
          print('âœ… ç¶²ç«™åœ°åœ–ç”Ÿæˆå®Œæˆ')
          "
          
          # æäº¤sitemap
          git add sitemap.xml || true
          if git diff --cached --quiet; then
            echo "ç¶²ç«™åœ°åœ–æ²’æœ‰è®Šæ›´"
          else
            git commit -m "æ›´æ–°ç¶²ç«™åœ°åœ– [$(date +'%Y-%m-%d %H:%M:%S')]"
            git push
          fi

      # æœ€å¾Œçš„çµæœé€šçŸ¥
      - name: å·¥ä½œæµåŸ·è¡Œçµæœé€šçŸ¥
        run: |
          echo "===== å·¥ä½œæµç¨‹åŸ·è¡Œå®Œæˆ ====="
          echo "åŸ·è¡Œæ™‚é–“: $(date '+%Y-%m-%d %H:%M:%S UTC')"
          echo "å°ç£æ™‚é–“: $(TZ='Asia/Taipei' date '+%Y-%m-%d %H:%M:%S %Z')"
          
          # é¡¯ç¤ºåŸ·è¡Œçµæœæ‘˜è¦
          echo ""
          echo "åŸ·è¡Œçµæœæ‘˜è¦:"
          echo "- Wordæ–‡æª”è™•ç†: ${{ steps.process_word.outputs.html_changed == 'true' && 'âœ… æˆåŠŸ' || 'â­ï¸ è·³éæˆ–ç„¡éœ€è™•ç†' }}"
          echo "- JSONæ–‡ä»¶æ›´æ–°: ${{ steps.update_blog_json.outputs.blog_json_updated == 'true' && 'âœ… æˆåŠŸ' || 'â­ï¸ è·³é' }}"
          
          # é¡¯ç¤ºç”Ÿæˆçš„æ–‡ä»¶çµ±è¨ˆ
          echo ""
          echo "æ–‡ä»¶çµ±è¨ˆ:"
          echo "- HTMLæ–‡ä»¶: $(find blog -name "*.html" 2>/dev/null | wc -l) å€‹"
          echo "- JSONæ–‡ä»¶: $(find assets/data -name "*.json" 2>/dev/null | wc -l) å€‹"
          echo "- å·²è™•ç†Wordæ–‡æª”: $(find word-docs/processed -name "*.docx" 2>/dev/null | wc -l) å€‹"
          
          # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤ä½†ä¸ä¸­æ–·
          echo ""
          echo "æ³¨æ„äº‹é …:"
          if [ "${{ steps.process_word.outputs.html_changed }}" == "false" ]; then
            echo "- Wordæ–‡æª”è™•ç†å¯èƒ½é‡åˆ°å•é¡Œï¼Œä½†å·¥ä½œæµç¨‹ä»æœƒç¹¼çºŒ"
          fi
          
          echo ""
          echo "ğŸ‰ å·¥ä½œæµç¨‹åŸ·è¡Œå®Œæˆï¼"