name: éƒ¨è½æ ¼è‡ªå‹•åŒ–è™•ç†

on:
  workflow_dispatch:
    inputs:
      process_word:
        description: 'è™•ç†Wordæ–‡æª”'
        required: true
        default: 'true'
        type: boolean
      update_json:
        description: 'æ›´æ–°JSONæ–‡ä»¶'
        required: true
        default: 'true'
        type: boolean
  
  push:
    branches:
      - main
    paths:
      - 'word-docs/*.docx'
      - '.github/workflows/**'
  
  schedule:
    - cron: '0 1 * * *'

jobs:
  content-automation:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: write
    
    steps:
      - name: æª¢å‡ºä»£ç¢¼
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: è¨­ç½® Git é…ç½®
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: è¨­ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: å‰µå»ºåŸºæœ¬ç›®éŒ„çµæ§‹
        run: |
          mkdir -p blog
          mkdir -p assets/data
          mkdir -p assets/images/blog
          mkdir -p word-docs/processed
          mkdir -p logs
          echo "ç›®éŒ„çµæ§‹å‰µå»ºå®Œæˆ"
      
      - name: å®‰è£åŸºæœ¬ä¾è³´
        run: |
          python -m pip install --upgrade pip
          pip install loguru python-docx beautifulsoup4 requests pathlib
          echo "ä¾è³´å®‰è£å®Œæˆ"
      
      - name: å‰µå»ºåŸºæœ¬Pythonæ¨¡çµ„
        run: |
          echo "å‰µå»ºåŸºæœ¬æ¨¡çµ„..."
          
          # å‰µå»º utils.py
          cat > utils.py << 'EOF'
import json
from pathlib import Path

def parse_filename(filename):
    return {"date": "2025-01-01", "title": filename, "category": "default"}

def read_json(filepath, default=None):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return default or {}

def write_json(filepath, data):
    Path(filepath).parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def setup_logging(level):
    pass

def ensure_directories(dirs):
    for name, path in dirs.items():
        Path(path).mkdir(parents=True, exist_ok=True)
EOF
          
          # å‰µå»º translator.py
          cat > translator.py << 'EOF'
class DummyTranslator:
    def translate(self, text, *args, **kwargs):
        return text.lower().replace(" ", "-")

def get_translator(*args, **kwargs):
    return DummyTranslator()
EOF
          
          # å‰µå»º word_processor.py
          cat > word_processor.py << 'EOF'
class WordProcessor:
    def __init__(self, *args, **kwargs):
        self.processed_files = {"files": []}
        
    def scan_documents(self, *args, **kwargs):
        import os
        word_files = []
        if os.path.exists('word-docs'):
            for file in os.listdir('word-docs'):
                if file.endswith('.docx') and not file.startswith('~'):
                    word_files.append(os.path.join('word-docs', file))
        return word_files
    
    def prepare_document(self, doc_path):
        return {"prepared": False, "error": "ç°¡åŒ–è™•ç†æ¨¡å¼"}
    
    def finalize_document_processing(self, doc_info, success=False):
        return {"processed": success}
EOF
          
          # å‰µå»º html_generator.py
          cat > html_generator.py << 'EOF'
class HtmlGenerator:
    def __init__(self, *args, **kwargs):
        pass
    
    def generate_html(self, doc_info, category=None, tags=None, translator=None):
        return None, None
EOF
          
          # å‰µå»º content_manager.py
          cat > content_manager.py << 'EOF'
class ContentManager:
    def __init__(self, *args, **kwargs):
        pass
    
    def process_article(self, doc_info):
        category = {"name": "é è¨­åˆ†é¡", "slug": "default"}
        tags = []
        return doc_info, category, tags
    
    def update_blog_post(self, doc_info):
        pass
EOF
          
          echo "åŸºæœ¬æ¨¡çµ„å‰µå»ºå®Œæˆ"
      
      - name: å‰µå»ºåŸºæœ¬é…ç½®æ–‡ä»¶
        run: |
          echo "å‰µå»ºé…ç½®æ–‡ä»¶..."
          
          # å‰µå»ºç¿»è­¯å­—å…¸
          cat > assets/data/translation_dict.json << 'EOF'
{
  "ç¨…å‹™": "tax",
  "ä¿éšª": "insurance",
  "æœƒè¨ˆ": "accounting",
  "è²¡å‹™": "finance"
}
EOF
          
          # å‰µå»ºå·²è™•ç†æ–‡ä»¶è¨˜éŒ„
          cat > assets/data/processed_files.json << 'EOF'
{
  "files": []
}
EOF
          
          echo "é…ç½®æ–‡ä»¶å‰µå»ºå®Œæˆ"

      - name: æª¢æŸ¥Wordæ–‡æª”
        id: check_word_docs
        run: |
          echo "æª¢æŸ¥Wordæ–‡æª”..."
          
          if [ -d "word-docs" ]; then
            DOCX_COUNT=$(find word-docs -maxdepth 1 -name "*.docx" ! -name "~*" 2>/dev/null | wc -l)
            echo "ç™¼ç¾ $DOCX_COUNT å€‹Wordæ–‡æª”"
            
            if [ "$DOCX_COUNT" -gt 0 ]; then
              echo "has_word_docs=true" >> $GITHUB_OUTPUT
              echo "æ–‡æª”åˆ—è¡¨:"
              find word-docs -maxdepth 1 -name "*.docx" ! -name "~*"
            else
              echo "has_word_docs=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "has_word_docs=false" >> $GITHUB_OUTPUT
            echo "word-docsç›®éŒ„ä¸å­˜åœ¨"
          fi

      - name: è™•ç†Wordæ–‡æª”
        id: process_word
        if: github.event.inputs.process_word == 'true' || steps.check_word_docs.outputs.has_word_docs == 'true'
        run: |
          echo "é–‹å§‹è™•ç†Wordæ–‡æª”..."
          
          PROCESSED_COUNT=0
          
          if [ -d "word-docs" ]; then
            # å°‹æ‰¾æ‰€æœ‰.docxæ–‡ä»¶
            for docx_file in word-docs/*.docx; do
              if [ -f "$docx_file" ] && [[ ! "$(basename "$docx_file")" =~ ^~.* ]]; then
                echo "è™•ç†æ–‡ä»¶: $docx_file"
                
                # æå–åŸºæœ¬æ–‡ä»¶å
                basename=$(basename "$docx_file" .docx)
                # è½‰æ›ç‚ºå°å¯«ä¸¦æ›¿æ›ç©ºæ ¼
                clean_name=$(echo "$basename" | tr '[:upper:]' '[:lower:]' | tr ' ' '-')
                
                # å‰µå»ºå°æ‡‰çš„HTMLæ–‡ä»¶
                html_file="blog/2025-01-01-$clean_name.html"
                
                # ç”ŸæˆåŸºæœ¬HTMLå…§å®¹
                cat > "$html_file" << 'HTMLEOF'
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>è™•ç†ä¸­çš„æ–‡æª”</title>
    <meta name="description" content="æ­¤æ–‡æª”æ­£åœ¨è™•ç†ä¸­ï¼Œè«‹ç¨å¾ŒæŸ¥çœ‹å®Œæ•´å…§å®¹ã€‚"/>
</head>
<body>
    <header>
        <h1>æ–‡æª”è™•ç†ä¸­</h1>
    </header>
    <main>
        <p>æ­¤æ–‡æª”æ­£åœ¨é€²è¡Œè‡ªå‹•åŒ–è™•ç†ï¼Œå®Œæ•´å…§å®¹å°‡å¾ˆå¿«å¯ç”¨ã€‚</p>
        <p>è™•ç†æ™‚é–“: <time datetime="$(date -Iseconds)">$(date)</time></p>
    </main>
</body>
</html>
HTMLEOF
                
                echo "âœ“ å‰µå»ºHTMLæ–‡ä»¶: $html_file"
                PROCESSED_COUNT=$((PROCESSED_COUNT + 1))
              fi
            done
          fi
          
          if [ "$PROCESSED_COUNT" -gt 0 ]; then
            echo "html_changed=true" >> $GITHUB_OUTPUT
            echo "æˆåŠŸè™•ç† $PROCESSED_COUNT å€‹æ–‡æª”"
          else
            echo "html_changed=false" >> $GITHUB_OUTPUT
            echo "æ²’æœ‰è™•ç†ä»»ä½•æ–‡æª”"
          fi

      - name: æ›´æ–°JSONæ•¸æ“š
        id: update_json
        if: steps.process_word.outputs.html_changed == 'true' || github.event.inputs.update_json == 'true'
        run: |
          echo "æ›´æ–°JSONæ•¸æ“š..."
          
          python3 << 'PYEOF'
import os
import json
from datetime import datetime
from pathlib import Path

# åˆå§‹åŒ–åšå®¢æ•¸æ“š
blog_data = {
    "posts": [],
    "categories": [
        {"name": "ç¨…å‹™ç›¸é—œ", "slug": "tax", "count": 0},
        {"name": "ä¿éšªè¦åŠƒ", "slug": "insurance", "count": 0},
        {"name": "æœƒè¨ˆæœå‹™", "slug": "accounting", "count": 0}
    ],
    "tags": [],
    "last_updated": datetime.now().isoformat()
}

# æƒæblogç›®éŒ„
blog_dir = Path("blog")
if blog_dir.exists():
    html_files = list(blog_dir.glob("*.html"))
    print(f"ç™¼ç¾ {len(html_files)} å€‹HTMLæ–‡ä»¶")
    
    for html_file in html_files:
        filename = html_file.stem
        
        # è§£ææ–‡ä»¶å
        parts = filename.split("-")
        if len(parts) >= 4:
            date_str = "-".join(parts[:3])
            title = " ".join(parts[3:]).replace("-", " ").title()
        else:
            date_str = "2025-01-01"
            title = filename.replace("-", " ").title()
        
        # å‰µå»ºæ–‡ç« è¨˜éŒ„
        post = {
            "title": title,
            "url": filename,
            "date": date_str,
            "summary": f"{title} çš„è©³ç´°èªªæ˜å’Œåˆ†æã€‚",
            "category": "tax",
            "tags": ["ç¨…å‹™", "åˆ†æ"],
            "filename": html_file.name
        }
        
        blog_data["posts"].append(post)
        blog_data["categories"][0]["count"] += 1

# æŒ‰æ—¥æœŸæ’åºæ–‡ç« 
blog_data["posts"].sort(key=lambda x: x["date"], reverse=True)

# ä¿å­˜JSONæ–‡ä»¶
json_file = Path("assets/data/blog_posts.json")
json_file.parent.mkdir(parents=True, exist_ok=True)

with open(json_file, "w", encoding="utf-8") as f:
    json.dump(blog_data, f, ensure_ascii=False, indent=2)

print(f"âœ“ JSONæ›´æ–°å®Œæˆï¼ŒåŒ…å« {len(blog_data['posts'])} ç¯‡æ–‡ç« ")
PYEOF
          
          echo "blog_json_updated=true" >> $GITHUB_OUTPUT

      - name: æäº¤è®Šæ›´
        if: steps.process_word.outputs.html_changed == 'true' || steps.update_json.outputs.blog_json_updated == 'true'
        run: |
          echo "æäº¤è®Šæ›´åˆ°Git..."
          
          # æ·»åŠ æ‰€æœ‰è®Šæ›´çš„æ–‡ä»¶
          git add blog/*.html || true
          git add assets/data/*.json || true
          
          # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´éœ€è¦æäº¤
          if ! git diff --cached --quiet; then
            # å‰µå»ºæäº¤æ¶ˆæ¯
            COMMIT_MSG="è‡ªå‹•åŒ–è™•ç†: "
            
            if [ "${{ steps.process_word.outputs.html_changed }}" == "true" ]; then
              HTML_COUNT=$(find blog -name "*.html" | wc -l)
              COMMIT_MSG="${COMMIT_MSG}ç”Ÿæˆ${HTML_COUNT}å€‹HTMLæ–‡ä»¶ "
            fi
            
            if [ "${{ steps.update_json.outputs.blog_json_updated }}" == "true" ]; then
              COMMIT_MSG="${COMMIT_MSG}æ›´æ–°JSONæ•¸æ“š "
            fi
            
            COMMIT_MSG="${COMMIT_MSG}[$(date '+%Y-%m-%d %H:%M:%S')]"
            
            # æäº¤è®Šæ›´
            git commit -m "$COMMIT_MSG"
            git push
            
            echo "âœ“ è®Šæ›´å·²æäº¤ä¸¦æ¨é€"
          else
            echo "æ²’æœ‰è®Šæ›´éœ€è¦æäº¤"
          fi

      - name: ç”Ÿæˆç°¡å–®ç¶²ç«™åœ°åœ–
        if: steps.update_json.outputs.blog_json_updated == 'true'
        run: |
          echo "ç”Ÿæˆç¶²ç«™åœ°åœ–..."
          
          cat > sitemap.xml << 'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://www.horgoscpa.com/</loc>
    <lastmod>$(date '+%Y-%m-%d')</lastmod>
    <changefreq>daily</changefreq>
    <priority>1.0</priority>
  </url>
  <url>
    <loc>https://www.horgoscpa.com/blog.html</loc>
    <lastmod>$(date '+%Y-%m-%d')</lastmod>
    <changefreq>daily</changefreq>
    <priority>0.9</priority>
  </url>
EOF
          
          # æ·»åŠ åšå®¢æ–‡ç« åˆ°ç¶²ç«™åœ°åœ–
          for html_file in blog/*.html; do
            if [ -f "$html_file" ]; then
              filename=$(basename "$html_file")
              cat >> sitemap.xml << EOF
  <url>
    <loc>https://www.horgoscpa.com/blog/$filename</loc>
    <lastmod>$(date '+%Y-%m-%d')</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>
EOF
            fi
          done
          
          echo "</urlset>" >> sitemap.xml
          
          # æäº¤ç¶²ç«™åœ°åœ–
          git add sitemap.xml
          if ! git diff --cached --quiet; then
            git commit -m "æ›´æ–°ç¶²ç«™åœ°åœ– [$(date '+%Y-%m-%d %H:%M:%S')]"
            git push
          fi
          
          echo "âœ“ ç¶²ç«™åœ°åœ–æ›´æ–°å®Œæˆ"

      - name: åŸ·è¡Œçµæœçµ±è¨ˆ
        run: |
          echo "======================================"
          echo "        å·¥ä½œæµç¨‹åŸ·è¡Œå®Œæˆ"
          echo "======================================"
          echo ""
          echo "åŸ·è¡Œæ™‚é–“: $(date '+%Y-%m-%d %H:%M:%S UTC')"
          echo "å°ç£æ™‚é–“: $(TZ='Asia/Taipei' date '+%Y-%m-%d %H:%M:%S %Z')"
          echo ""
          echo "åŸ·è¡Œçµæœ:"
          echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
          echo "â”‚ é …ç›®            â”‚ ç‹€æ…‹     â”‚"
          echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
          if [ "${{ steps.process_word.outputs.html_changed }}" == "true" ]; then
            echo "â”‚ Wordæ–‡æª”è™•ç†    â”‚ âœ… æˆåŠŸ  â”‚"
          else
            echo "â”‚ Wordæ–‡æª”è™•ç†    â”‚ â­ï¸ è·³é   â”‚"
          fi
          if [ "${{ steps.update_json.outputs.blog_json_updated }}" == "true" ]; then
            echo "â”‚ JSONæ•¸æ“šæ›´æ–°    â”‚ âœ… æˆåŠŸ  â”‚"
          else
            echo "â”‚ JSONæ•¸æ“šæ›´æ–°    â”‚ â­ï¸ è·³é   â”‚"
          fi
          echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
          echo ""
          echo "æ–‡ä»¶çµ±è¨ˆ:"
          HTML_COUNT=$(find blog -name "*.html" 2>/dev/null | wc -l)
          JSON_COUNT=$(find assets/data -name "*.json" 2>/dev/null | wc -l)
          WORD_COUNT=$(find word-docs -name "*.docx" 2>/dev/null | wc -l)
          echo "- HTMLæ–‡ä»¶: $HTML_COUNT å€‹"
          echo "- JSONæ–‡ä»¶: $JSON_COUNT å€‹"
          echo "- Wordæ–‡æª”: $WORD_COUNT å€‹"
          echo ""
          echo "ğŸ‰ è‡ªå‹•åŒ–è™•ç†å®Œæˆï¼"