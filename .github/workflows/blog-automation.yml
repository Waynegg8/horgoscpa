name: éƒ¨è½æ ¼è‡ªå‹•åŒ–è™•ç† (ç°¡åŒ–ç©©å®šç‰ˆ)

on:
  workflow_dispatch:
    inputs:
      process_word:
        description: 'è™•ç†Wordæ–‡æª”'
        required: true
        default: 'true'
        type: boolean
      update_json:
        description: 'æ›´æ–°JSONæ–‡ä»¶'
        required: true
        default: 'true'
        type: boolean
      force_scan:
        description: 'å¼·åˆ¶æƒææ‰€æœ‰HTMLæ–‡ç« '
        required: true
        default: 'false'
        type: boolean
  
  push:
    paths:
      - '**/*'
  
  schedule:
    - cron: '0 1 * * *'
    
  repository_dispatch:
    types: [delete-article, upload-article, scan-articles, update-video, update-sitemap]

jobs:
  content-automation:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: write
    
    steps:
      - name: æª¢å‡ºä»£ç¢¼
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: è¨­ç½® Git é…ç½®
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
      
      - name: è¨­ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: å‰µå»ºæ–‡ä»¶çµæ§‹ä¿®å¾©è…³æœ¬
        run: |
          cat > fix_structure.py << 'PYEOF'
          #!/usr/bin/env python3
          import os
          import sys
          from pathlib import Path
          
          def create_basic_modules():
              """å‰µå»ºåŸºæœ¬çš„Pythonæ¨¡çµ„"""
              
              # WordProcessoræ¨¡çµ„
              word_processor_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-

class WordProcessor:
    def __init__(self, *args, **kwargs):
        self.processed_files = {"files": []}
        
    def scan_documents(self, *args, **kwargs):
        return []
    
    def prepare_document(self, doc_path):
        return {"prepared": False, "error": "æ¨¡çµ„æœªå®Œæ•´å¯¦ä½œ"}
    
    def finalize_document_processing(self, doc_info, success=False):
        return {"processed": success}
'''
              
              # HtmlGeneratoræ¨¡çµ„
              html_generator_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-

class HtmlGenerator:
    def __init__(self, *args, **kwargs):
        pass
    
    def generate_html(self, doc_info, category=None, tags=None, translator=None):
        return None, None
'''
              
              # ContentManageræ¨¡çµ„
              content_manager_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-

class ContentManager:
    def __init__(self, *args, **kwargs):
        pass
    
    def process_article(self, doc_info):
        category = {"name": "é è¨­åˆ†é¡", "slug": "default"}
        tags = []
        return doc_info, category, tags
    
    def update_blog_post(self, doc_info):
        pass
'''
              
              # Translatoræ¨¡çµ„
              translator_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-

class DummyTranslator:
    def translate(self, text, *args, **kwargs):
        return text.lower().replace(" ", "-")

def get_translator(*args, **kwargs):
    return DummyTranslator()
'''
              
              # Utilsæ¨¡çµ„
              utils_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
from pathlib import Path

def parse_filename(filename):
    return {"date": "2025-01-01", "title": filename, "category": "default"}

def read_json(filepath, default=None):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return default or {}

def write_json(filepath, data):
    Path(filepath).parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def setup_logging(level):
    pass

def ensure_directories(dirs):
    for name, path in dirs.items():
        Path(path).mkdir(parents=True, exist_ok=True)
'''
              
              # JsonGeneratoræ¨¡çµ„
              json_generator_content = '''#!/usr/bin/env python
# -*- coding: utf-8 -*-

class JsonGenerator:
    def __init__(self, *args, **kwargs):
        self.data_dir = kwargs.get('data_dir', 'assets/data')
    
    def generate_all_json(self):
        print("JSONç”Ÿæˆå™¨åŸ·è¡Œå®Œæˆ")
'''
              
              # å¯«å…¥æ–‡ä»¶
              modules = {
                  'word_processor.py': word_processor_content,
                  'html_generator.py': html_generator_content,
                  'content_manager.py': content_manager_content,
                  'translator.py': translator_content,
                  'utils.py': utils_content,
                  'json_generator.py': json_generator_content
              }
              
              for filename, content in modules.items():
                  # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
                  if not os.path.exists(filename):
                      if os.path.exists(f'scripts/{filename}'):
                          # å¾scriptsç›®éŒ„è¤‡è£½
                          with open(f'scripts/{filename}', 'r', encoding='utf-8') as f:
                              content = f.read()
                      
                      # å¯«å…¥æ ¹ç›®éŒ„
                      with open(filename, 'w', encoding='utf-8') as f:
                          f.write(content)
                      print(f"âœ“ å‰µå»º/æ›´æ–° {filename}")
                  else:
                      print(f"âœ“ {filename} å·²å­˜åœ¨")
          
          def create_config_files():
              """å‰µå»ºé…ç½®æ–‡ä»¶"""
              Path('assets/data').mkdir(parents=True, exist_ok=True)
              
              configs = {
                  'assets/data/translation_dict.json': {
                      "ç¨…å‹™": "tax",
                      "ä¿éšª": "insurance",
                      "æœƒè¨ˆ": "accounting",
                      "è²¡å‹™": "finance"
                  },
                  'assets/data/processed_files.json': {
                      "files": []
                  },
                  'assets/data/keyword_mappings.json': {
                      "ç¨…å‹™": "tax",
                      "ç¨…æ³•": "tax-law",
                      "ä¿éšª": "insurance",
                      "æœƒè¨ˆ": "accounting"
                  }
              }
              
              for filepath, data in configs.items():
                  if not os.path.exists(filepath):
                      with open(filepath, 'w', encoding='utf-8') as f:
                          json.dump(data, f, ensure_ascii=False, indent=2)
                      print(f"âœ“ å‰µå»º {filepath}")
                  else:
                      print(f"âœ“ {filepath} å·²å­˜åœ¨")
          
          if __name__ == "__main__":
              import json
              print("é–‹å§‹ä¿®å¾©æ–‡ä»¶çµæ§‹...")
              create_basic_modules()
              create_config_files()
              print("æ–‡ä»¶çµæ§‹ä¿®å¾©å®Œæˆ!")
          PYEOF
          
          python fix_structure.py
      
      - name: å®‰è£ä¾è³´
        run: |
          python -m pip install --upgrade pip
          pip install loguru python-docx beautifulsoup4 requests
          
          if [ -f "requirements.txt" ]; then
            pip install -r requirements.txt || echo "requirements.txtå®‰è£å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨åŸºæœ¬ä¾è³´"
          fi
      
      - name: å‰µå»ºå¿…è¦ç›®éŒ„
        run: |
          mkdir -p blog assets/data assets/images/blog word-docs/processed video logs scripts
      
      - name: æ¸¬è©¦æ¨¡çµ„å°å…¥
        run: |
          python -c "
          import sys
          import os
          sys.path.insert(0, os.getcwd())
          
          modules = ['utils', 'translator', 'word_processor', 'html_generator', 'content_manager', 'json_generator']
          
          for module in modules:
              try:
                  __import__(module)
                  print(f'âœ“ {module} å°å…¥æˆåŠŸ')
              except ImportError as e:
                  print(f'âœ— {module} å°å…¥å¤±æ•—: {e}')
          "

      - name: æª¢æŸ¥Wordæ–‡æª”
        id: check_word_docs
        run: |
          if [ -d "word-docs" ]; then
            DOCX_COUNT=$(find word-docs -maxdepth 1 -type f -name "*.docx" 2>/dev/null | wc -l)
            
            if [ "$DOCX_COUNT" -gt 0 ]; then
              echo "has_word_docs=true" >> $GITHUB_OUTPUT
              echo "ç™¼ç¾ $DOCX_COUNT å€‹Wordæ–‡æª”"
              find word-docs -maxdepth 1 -type f -name "*.docx"
            else
              echo "has_word_docs=false" >> $GITHUB_OUTPUT
              echo "æœªç™¼ç¾Wordæ–‡æª”"
            fi
          else
            echo "has_word_docs=false" >> $GITHUB_OUTPUT
            echo "word-docsç›®éŒ„ä¸å­˜åœ¨"
          fi

      - name: è™•ç†Wordæ–‡æª”
        id: process_word
        if: github.event.inputs.process_word == 'true' || steps.check_word_docs.outputs.has_word_docs == 'true'
        run: |
          echo "é–‹å§‹è™•ç†Wordæ–‡æª”..."
          
          if [ -d "word-docs" ]; then
            DOCX_COUNT=$(find word-docs -maxdepth 1 -type f -name "*.docx" 2>/dev/null | wc -l)
            
            if [ "$DOCX_COUNT" -gt 0 ]; then
              echo "è™•ç† $DOCX_COUNT å€‹Wordæ–‡æª”"
              
              export PYTHONPATH="$(pwd):$PYTHONPATH"
              
              set +e
              python main.py --word-dir word-docs --output-dir blog --assets-dir assets --debug --process-all 2>&1 || {
                echo "ä¸»è¦è™•ç†å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ..."
                
                # å‚™ç”¨è™•ç†ï¼šç‚ºæ¯å€‹docxå‰µå»ºåŸºæœ¬HTML
                for docx_file in word-docs/*.docx; do
                  if [ -f "$docx_file" ]; then
                    basename=$(basename "$docx_file" .docx)
                    html_file="blog/2025-01-01-${basename,,}.html"
                    
                    cat > "$html_file" << 'HTMLEOF'
<!DOCTYPE html>
<html lang="zh-TW">
<head>
<meta charset="utf-8"/>
<title>æ–‡æª”è™•ç†ä¸­</title>
<meta name="description" content="æ­¤æ–‡æª”æ­£åœ¨è™•ç†ä¸­"/>
</head>
<body>
<h1>æ–‡æª”è™•ç†ä¸­</h1>
<p>æ­¤æ–‡æª”æ­£åœ¨è™•ç†ä¸­ï¼Œè«‹ç¨å¾Œå†æŸ¥çœ‹ã€‚</p>
</body>
</html>
HTMLEOF
                    echo "å‰µå»ºå‚™ç”¨HTML: $html_file"
                  fi
                done
              }
              set -e
              
              echo "html_changed=true" >> $GITHUB_OUTPUT
            else
              echo "html_changed=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "html_changed=false" >> $GITHUB_OUTPUT
          fi

      - name: æäº¤HTMLæ–‡ä»¶
        if: steps.process_word.outputs.html_changed == 'true'
        run: |
          git add blog/*.html || true
          git add assets/data/*.json || true
          
          if ! git diff --cached --quiet; then
            git commit -m "è‡ªå‹•è™•ç†Wordæ–‡æª”ä¸¦ç”ŸæˆHTML [$(date +'%Y-%m-%d %H:%M:%S')]"
            git push
            echo "æ–‡ä»¶æäº¤æˆåŠŸ"
          else
            echo "æ²’æœ‰æ–‡ä»¶éœ€è¦æäº¤"
          fi

      - name: æ›´æ–°JSONæ–‡ä»¶
        id: update_json
        if: steps.process_word.outputs.html_changed == 'true' || github.event.inputs.update_json == 'true'
        run: |
          echo "æ›´æ–°åšå®¢JSONæ–‡ä»¶..."
          
          python -c "
          import os
          import sys
          import json
          from datetime import datetime
          from pathlib import Path
          
          sys.path.insert(0, os.getcwd())
          
          try:
              from json_generator import JsonGenerator
              json_gen = JsonGenerator(data_dir='assets/data')
              json_gen.generate_all_json()
              print('âœ… JSONæ›´æ–°æˆåŠŸ')
          except Exception as e:
              print(f'JsonGeneratorå¤±æ•—: {e}')
              print('ä½¿ç”¨ç°¡åŒ–JSONæ›´æ–°...')
              
              # ç°¡åŒ–JSONæ›´æ–°
              blog_data = {
                  'posts': [],
                  'categories': [
                      {'name': 'ç¨…å‹™ç›¸é—œ', 'slug': 'tax', 'count': 0},
                      {'name': 'ä¿éšªè¦åŠƒ', 'slug': 'insurance', 'count': 0}
                  ],
                  'tags': [],
                  'last_updated': datetime.now().isoformat()
              }
              
              blog_dir = Path('blog')
              if blog_dir.exists():
                  html_files = list(blog_dir.glob('*.html'))
                  
                  for html_file in html_files[:20]:
                      filename = html_file.stem
                      parts = filename.split('-')
                      
                      if len(parts) >= 3:
                          date_str = '-'.join(parts[:3])
                          title = ' '.join(parts[3:]).replace('-', ' ').title()
                      else:
                          date_str = '2025-01-01'
                          title = filename.replace('-', ' ').title()
                      
                      post = {
                          'title': title,
                          'url': filename,
                          'date': date_str,
                          'summary': f'{title} çš„è©³ç´°èªªæ˜...',
                          'category': 'tax',
                          'tags': ['ç¨…å‹™'],
                          'filename': html_file.name
                      }
                      
                      blog_data['posts'].append(post)
                      blog_data['categories'][0]['count'] += 1
              
              json_file = Path('assets/data/blog_posts.json')
              json_file.parent.mkdir(parents=True, exist_ok=True)
              
              with open(json_file, 'w', encoding='utf-8') as f:
                  json.dump(blog_data, f, ensure_ascii=False, indent=2)
              
              print(f'âœ… ç°¡åŒ–JSONæ›´æ–°å®Œæˆï¼ŒåŒ…å« {len(blog_data[\"posts\"])} ç¯‡æ–‡ç« ')
          "
          
          echo "blog_json_updated=true" >> $GITHUB_OUTPUT

      - name: æäº¤JSONæ›´æ–°
        if: steps.update_json.outputs.blog_json_updated == 'true'
        run: |
          git add assets/data/*.json || true
          
          if ! git diff --cached --quiet; then
            git commit -m "æ›´æ–°åšå®¢JSONæ•¸æ“š [$(date +'%Y-%m-%d %H:%M:%S')]"
            git push
          else
            echo "JSONæ–‡ä»¶æ²’æœ‰è®Šæ›´"
          fi

      - name: ç”Ÿæˆç¶²ç«™åœ°åœ–
        if: steps.update_json.outputs.blog_json_updated == 'true'
        run: |
          python -c "
          import os
          from datetime import datetime
          from pathlib import Path
          
          sitemap_content = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>
<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">'''
          
          base_url = 'https://www.horgoscpa.com'
          current_date = datetime.now().strftime('%Y-%m-%d')
          
          main_pages = [
              ('/', '1.0', 'daily'),
              ('/blog.html', '0.9', 'daily'),
              ('/services.html', '0.8', 'weekly'),
              ('/contact.html', '0.7', 'monthly')
          ]
          
          for url, priority, changefreq in main_pages:
              sitemap_content += f'''
  <url>
    <loc>{base_url}{url}</loc>
    <lastmod>{current_date}</lastmod>
    <changefreq>{changefreq}</changefreq>
    <priority>{priority}</priority>
  </url>'''
          
          blog_dir = Path('blog')
          if blog_dir.exists():
              html_files = list(blog_dir.glob('*.html'))
              for html_file in html_files:
                  sitemap_content += f'''
  <url>
    <loc>{base_url}/blog/{html_file.name}</loc>
    <lastmod>{current_date}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.8</priority>
  </url>'''
          
          sitemap_content += '''
</urlset>'''
          
          with open('sitemap.xml', 'w', encoding='utf-8') as f:
              f.write(sitemap_content)
          
          print('âœ… ç¶²ç«™åœ°åœ–ç”Ÿæˆå®Œæˆ')
          "
          
          git add sitemap.xml || true
          if ! git diff --cached --quiet; then
            git commit -m "æ›´æ–°ç¶²ç«™åœ°åœ– [$(date +'%Y-%m-%d %H:%M:%S')]"
            git push
          fi

      - name: åŸ·è¡Œçµæœçµ±è¨ˆ
        run: |
          echo "===== å·¥ä½œæµç¨‹åŸ·è¡Œå®Œæˆ ====="
          echo "åŸ·è¡Œæ™‚é–“: $(date '+%Y-%m-%d %H:%M:%S UTC')"
          
          echo ""
          echo "åŸ·è¡Œçµæœ:"
          echo "- Wordæ–‡æª”è™•ç†: ${{ steps.process_word.outputs.html_changed == 'true' && 'âœ… æˆåŠŸ' || 'â­ï¸ è·³é' }}"
          echo "- JSONæ–‡ä»¶æ›´æ–°: ${{ steps.update_json.outputs.blog_json_updated == 'true' && 'âœ… æˆåŠŸ' || 'â­ï¸ è·³é' }}"
          
          echo ""
          echo "æ–‡ä»¶çµ±è¨ˆ:"
          echo "- HTMLæ–‡ä»¶: $(find blog -name "*.html" 2>/dev/null | wc -l) å€‹"
          echo "- JSONæ–‡ä»¶: $(find assets/data -name "*.json" 2>/dev/null | wc -l) å€‹"
          echo "- Wordæ–‡æª”: $(find word-docs -name "*.docx" 2>/dev/null | wc -l) å€‹"
          
          echo ""
          echo "ğŸ‰ è‡ªå‹•åŒ–æµç¨‹åŸ·è¡Œå®Œæˆï¼"