name: Official Website Crawler

on:
  repository_dispatch:
    types: [official_crawl_request]

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml
          
      - name: Run official crawler
        env:
          ZENSCRAPE_API_KEY: ${{ secrets.ZENSCRAPE_API_KEY }}
        run: |
          mkdir -p crawler-results
          echo "Crawl ID: ${{ github.event.client_payload.crawl_id }}"
          echo "Config: ${{ toJson(github.event.client_payload.config) }}"
          python scripts/official_crawler.py "${{ github.event.client_payload.crawl_id }}" '${{ toJson(github.event.client_payload.config) }}'
          
      - name: Commit and push results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"
          git pull origin main --rebase
          git add crawler-results/
          git commit -m "Add official site crawl results: ${{ github.event.client_payload.crawl_id }}" || echo "No changes to commit"
          git push