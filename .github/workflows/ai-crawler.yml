name: AI Crawler

on:
  repository_dispatch:
    types: [crawl_request]

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 google-generativeai
          
      - name: Run search crawler
        env:
          GOOGLE_SEARCH_API_KEY: ${{ secrets.GOOGLE_SEARCH_API_KEY }}
          GOOGLE_SEARCH_ENGINE_ID: ${{ secrets.GOOGLE_SEARCH_ENGINE_ID }}
        run: |
          mkdir -p crawler-results
          python scripts/crawler.py "${{ github.event.client_payload.query }}" "${{ github.event.client_payload.request_id }}"
          
      - name: Run content crawler with ZenScrape
        env:
          ZENSCRAPE_API_KEY: ${{ secrets.ZENSCRAPE_API_KEY }}
        run: |
          python scripts/content_crawler.py "${{ github.event.client_payload.request_id }}"
          
      - name: Analyze content with Gemini
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python scripts/content_analyzer.py "${{ github.event.client_payload.query }}" "${{ github.event.client_payload.request_id }}"
          
      - name: Commit and push results
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"
          git pull origin main --rebase
          git add crawler-results/
          git commit -m "Add analyzed results for query: ${{ github.event.client_payload.query }}" || echo "No changes to commit"
          git push